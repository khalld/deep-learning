\documentclass[11pt]{article}
\usepackage{graphicx}
\graphicspath{ {./images/} }

\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{hyperref}

\usepackage{sectsty}
\usepackage{graphicx}
\usepackage[font=small,labelfont=bf]{caption} % Required for specifying captions to tables and figures

% Margins
\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

% norm function
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}

\title{ %
\includegraphics[width=0.4\textwidth]{UniCT-Logo-Nero}~\\
Trashbin Triplet Classifier \\ 
\large Progetto Deep Learning (LM-18) \\ Università degli Studi di Catania - A.A 2021/2022 \\
}
\author{ Danilo Leocata - 1000022576 \\ Docenti: Giovanni Maria Farinella, Antonino Furnari}
\date{\today}

\begin{document}

\maketitle	
\pagebreak

%--Paper--

\section{Introduzione}

L'obiettivo dell'elaborato è implementare una procedura di \textit{Metric Learning} per classificare la 
capienza rimanente di secchi della spazzatura in: pieno, vuoto, a metà.

Il dataset è stato preso da un precedente progetto (\href{https://github.com/khalld/trashbin-classifier}{https://github.com/khalld/trashbin-classifier})
ed è disponibile al seguente indirizzo: \ \ \ \ 

\href{https://drive.google.com/drive/folders/1LmN-fXWZ8UpRkLeMjbootN46V9AHaE4x}{https://drive.google.com/drive/folders/1LmN-fXWZ8UpRkLeMjbootN46V9AHaE4x}.

Il progetto è stato implementato utilizzando \texttt{python v3.9.9} e \texttt{pytorch-lighting v1.6.3}. Il modello è stato allenato utilizzando un MacBook Pro (16-inch, 2019) con processore Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz, RAM: 16 GB 2667 MHz DDR4 e GPU AMD Radeon Pro 5300M 4 GB
Intel UHD Graphics 630 1536 MB. Sfortunatamente, ad oggi, il modello di GPU non è supportato per l'accelerazione del training e di conseguenza è stato effettuato su CPU.

Il codice è ampiamente commentato, in particolare può essere diviso concettualmente in 3 parti:

\begin{enumerate}
    \item \texttt{dataset.ipynb} Notebook Jupiter realizzato per mostrare il funzionamento delle funzioni implementate per adattare il dataset al task specifico
    \item \texttt{training-script.py} Script utilizzato per effettuare il training del modello
    \item \texttt{main.ipynb} Notebook Jupiter esplicativo, realizzato per visualizzare le performance ed effettuarne la valutazione (partendo da un \texttt{.ckpt})
\end{enumerate}

Nella repository (
\href{https://github.com/khalld/triplet-trashbin-classifier}{https://github.com/khalld/triplet-trashbin-classifier} )
è stato caricato solo il \texttt{.ckpt} del modello finale. Tutti i modelli ed i logs di tensorboard ottenuti sono
stati caricati su Google Drive: \href{https://drive.google.com/file/d/1vgALpclAQs7xSMj2BkQJxj770hXyJm4-}{https://drive.google.com/file/d/1vgALpclAQs7xSMj2BkQJxj770hXyJm4-}

\pagebreak

\section{Architettura}

Per il raggiungimento dell'obiettivo assegnato, è stato trovato opportuno
l'utilizzo di una \textit{Rete Triplet}, dato che l'obbiettivo è
massimizzare la distanza inter-classe degli oggetti
e quest'ultima dovrebbe permettere di ottenere un criterio di training più forte rispetto a quello
delle reti siamesi.

Una rete di tipo Triplet ha un criterio di training più forte, in quanto, offre
sempre un esempio positivo e negativo relativo
al medesimo elemento di ancora. Inoltre, questo approccio dovrebbe garantire
di massimizzare la distanza tra 'metà-vuoto' e 'metà-pieno' in modo migliore rispetto alla rete siamese.

\begin{center}
    \begin{minipage}{0.6\linewidth}
    \includegraphics[width=\linewidth]{01.png}
    \end{minipage}
    \captionof{figure}{Esempio del risultato che si vuole ottenere}
\end{center}

L'architetura di una rete Triplet è composta da tre rami identici, che condividono gli stessi pesi e mappano gli elementi in codici $\Phi(I_i)$, $\Phi(I_j)$, $\Phi(I_k)$.

\begin{center}
    \begin{minipage}{0.5\linewidth}
    \includegraphics[width=\linewidth]{02.png}
    \end{minipage}
    \captionof{figure}{Architettura rete triplet}
\end{center}


Prende in input una tripletta di elementi $(I_i, I_j, I_k)$ che sono:

\begin{itemize}
    \item L'ancora $I_i$ 
    \item L'esempio positivo $I_j$ (che in breve ha la stessa classe di $I_i$)
    \item L'esempio negativo $I_k$, cioé un elemento diverso dalle classi di $I_i$, $I_j$
\end{itemize}

In breve, la distanza dall'ancora al positivo è minimizzata e
la distanza dall'ancora al negativo è massimizzata.
Il modello farà in modo che una coppia di
campioni con le stesse etichette abbia una distanza inferiore
rispetto a una coppia di campioni con etichette diverse.

\subsection{Scelta del modello}

Come feature extractor è stata utilizzata
una \textbf{SqueezeNet} pre-trained senza il layer di classificazione.

\begin{center}
    \begin{minipage}{0.48\linewidth}
    \includegraphics[width=\linewidth]{03.png}
    \end{minipage}
    \captionof{figure}{Architettura SqueezeNet}
\end{center}

Nel progetto precedente
sono stati presi in esame alcuni modelli pretrained, disponibili su
\texttt{torchvision.models}, per tale motivo,
è stato più conveniente utilizzare \texttt{SqueezeNet}, che aveva comunque ottenuto il miglior risultato
in termini di tempo, esecuzione e validazione.

Inizialmente, nonostante la maggiore potenza computazionale rispetto allo studio precedente,
sono state effettuate delle prove utilizzando \texttt{MobileNetV2}, ma quest'ultima richiedeva
circa il doppio del tempo di \texttt{SqueezeNet}. In particolare, il completamento di un'epoca utilizzando \texttt{MobileNetV2} richiedeva 70 minuti
contro i 35/40 di \texttt{SqueezeNet v1} per immagini a colori \texttt{224x224}. Approssimando ed effettuando un training di 60 epoche \texttt{SqueezeNet v1} impiegherebbe 30 ore contro le 70 di \texttt{MobileNetV2}.

\subsection{Ottimizzazione del modello}

Sono state utilizzate funzioni, presenti su \texttt{pytorch-lighting} per trovare automaticamente i parametri da usare per il training del modello.
Nel dettaglio:

\begin{itemize}
    \item {\textbf{Batch Size Finder}: 
        impiegato per evitare problemi in memoria durante il training. Viene utilizzato
        per trovare la dimensione batch più grande, che si adatta alla memoria. In questo caso il pc supportava batch di dimensioni fino a \textbf{6600}. I lotti di grandi
        dimensioni spesso producono una migliore stima dei gradienti,
        ma possono anche comportare tempi di addestramento più lunghi. Dopo diverse prove e data la dimension esigua del dataset è stato
        opportuno fissarla a \textbf{256}; 
    }
    \item {\textbf{Learning Rate Finder}: selezionare un learning rate è essenziale sia per ottenere
        prestazioni migliori, che per una convergenza più rapida. Da documentazione,
        il \textit{learning rate finder} esegue una piccola run dove il learning rate viene aumentato dopo ogni batch elaborato
        e viene registrata la loss corrispondente.
    }
\end{itemize}

\section{Dataset}

Si è presentata la necessità di riadattare il dataset in triplette: ad ogni elemento di \textbf{ancora} verrà
associato un elemento \textbf{positivo} ed uno \textbf{negativo}, che sarà scelto randomicamente 
(ad esempio, se l'ancora è della classe 'vuoto', l'elemento negativo sarà 'pieno' o 'mezzo'). Per
questo, sono state implementate delle funzioni ad-hoc il cui utilizzo è documentato su \texttt{dataset.ipynb}. 

\begin{center}
    \begin{minipage}{0.6\linewidth}
    \includegraphics[width=\linewidth]{triplet_dataset.png}
    \end{minipage}
    \captionof{figure}{Dataset organizzato in triplette}
\end{center}

Effettuando vari test, è stato trovato più efficiente salvare il dataset generato in
\texttt{.csv}, evitando di memorizzare le triplette in memoria. Si nota che, per incrementare
la \textbf{generalizzazione}, sarebbe utile avere a disposizione diversi
\texttt{.csv} del dataset adattato ed alternare le varie versioni del dataset dopo un certo numero di epoche, 
in quanto, la funzione è stata implementata in modo tale che le triplette generate siano diverse ad ogni esecuzione del codice. Nel nostro caso, viene utilizzata
una versione per le prime 30 epoche e successivamente viene cambiato ogni 15.

\pagebreak
\section{Scelta della loss}

Per il training della rete siamese sono state prese in esame due loss differenti (disponibili su \texttt{torch.nn})

\subsection{Triplet margin loss}
Prende in input i tensori $x_1$, $x_2$, $x_3$ ed un $margin$ con un valore $> 0$,
la \textbf{Triplet margin loss} viene impiegata quando si vuole misurare una similitudine tra i samples.
Una tripletta è composta da $a$ (ancora), $p$ (positivo) ed $n$ (negativo). 
\begin{center}
    \ \
    $L(a,p,n) = \max{ \{ d(a_i, p_i) - d(a_i, n_i) + margin, 0 \} }$, dove \ \
    \\
    $d(x_i, y_i) = \|| x_i - y_i ||\ _p$
    \ \
\end{center}

\subsection{Triplet margin with distance loss}
Prende in input i tensori $a$ (ancora), $p$ (positivo) ed $n$ (negativo) ed una funzione a valori
reali non negativa chiamata \textit{funzione di distanza} $d$.
La \textbf{triplet margin with distance loss} può essere descritta dalla seguente formula:

\begin{center}
    $l(a,p,n) = L = { \{ l_1, \ldots, l_N \}}^T, l_i = \max{\{ d(a_i, p_i) - d(a_i, n_i) + margin, 0 \}} $
\end{center}

dove:

\begin{enumerate}
    \item $N$ è la dimensione del batch;
    \item {$d$ è una funzione non negativa a valori reali che quantifica la vicinanza di due tensori riferito
    alla funzione di distanza. Calcola la relazione tra l'ancora e l'esempio positivo
    (distanza positiva) e l'ancora e l'esempio negativo (distanza negativa);}
    \item {$margin$ 
        è un margine non negativo che rappresenta la differenza minima
        tra le distanze positive e negative;
    }
    \item Il tensore di input ha $N$ elementi, ognuno del quale può essere di qualsiasi forma, che la funzione di distanza può gestire.

    \item {
        Di default la funzione di distanza utilizzata è la Paiwrise Distance Funtion,
        che calcola la distanza tra i vettori $v_1$ e $v_2$ usando la p-norm:
    }
    \subitem {
        \begin{center}
            $ \| x \| _p = ( \sum^n_{i=1} |x_i|^p )^{\frac{1}{p}} $
        \end{center}
    }

\end{enumerate}


\pagebreak
\section{Training}

Durante le prime fasi di training sono state effettuate delle prove con e senza \textbf{data augmentation}. Inizialmente, la data augmentation applicata
era quella del progetto precedentemente citato, che, comunque, non ha fornito miglioramenti (si nota che nei grafici sottostanti, a 0 corrisponde la classe 'vuoto',
ad 1 'metà' e a 2 'pieno'). Sono stati estratti randomicamente dei campioni dal dataset di test ed è stata effettuata una predizione
sulle etichette utilizzando \textbf{Nearest Neighbor}. Le feature sono state estratte utilizzando varie versioni del modello allenato (utilizzando la variante con \textbf{Triplet Margin Loss}). Di seguito degli \textit{embedding T-SNE}:

\begin{center}
    \begin{minipage}{0.3\linewidth}
    \includegraphics[width=\linewidth]{04.png}
    \end{minipage}
    \begin{minipage}{0.3\linewidth}
    \includegraphics[width=\linewidth]{05.png}
    \end{minipage}
    \begin{minipage}{0.3\linewidth}
    \includegraphics[width=\linewidth]{06.png}
    \end{minipage}
    \captionof{figure}{T-SNE embeddings \textbf{senza data augmentation} dopo 0, 10, 30 epoche di training}
\end{center}


\begin{center}
    \begin{minipage}{0.3\linewidth}
    \includegraphics[width=\linewidth]{07.png}
    \end{minipage}
    \begin{minipage}{0.3\linewidth}
    \includegraphics[width=\linewidth]{08.png}
    \end{minipage}
    \begin{minipage}{0.3\linewidth}
    \includegraphics[width=\linewidth]{09.png}
    \end{minipage}
    \captionof{figure}{T-SNE embeddings \textbf{con data augmentation forte} dopo: 0, 30, 60 epoche di training}
\end{center}

Dai grafici di sopra si evince che con una data augmentation (troppo) forte il modello non riesce a trasformare correttamente lo spazio di input per massimizzare la distanza inter classe (elementi diversi sono lontani)
e minimizzare la distanza intra-classe (elementi simili sono vicini). Dopo numerose prove, è stato
trovato efficiente, in modo da preservarne le feature estratte applicare solamente \texttt{RandomCrop()} e \texttt{RandomPerspective} al dataset di training e \texttt{CenterCrop} al dataset di test.

\pagebreak

Gli errori classificazione ottenuti dalle loss due loss sono riassunti nella seguente tabella:

\begin{center}
    \begin{tabular}{ | l | l | l | p{5cm} |}
    \hline
    Epoch & Triplet Margin Loss & Triplet Margin With Distance Loss \\ \hline
    0 & 0.677 & 0.739 \\ \hline
    15 & 0.936 & 0.792: \\ \hline
    30 & 0.900 & 0.894  \\
    \hline
    \end{tabular}
\end{center}

\begin{center}
    \begin{minipage}{0.3\linewidth}
    \includegraphics[width=\linewidth]{TML-TSNE-0.png}
    \end{minipage}
    \begin{minipage}{0.3\linewidth}
    \includegraphics[width=\linewidth]{TML-TSNE-15.png}
    \end{minipage}
    \begin{minipage}{0.3\linewidth}
    \includegraphics[width=\linewidth]{TML-TSNE-30.png}
    \end{minipage}
    \captionof{figure}{T-SNE embeddings ottenuti con \textbf{Triplet Margin Loss} dopo: 0, 15, 30 epoche di training}    
\end{center}

\begin{center}
    \begin{minipage}{0.3\linewidth}
    \includegraphics[width=\linewidth]{TMWDL-TSNE-0.png}
    \end{minipage}
    \begin{minipage}{0.3\linewidth}
    \includegraphics[width=\linewidth]{TMWDL-TSNE-15.png}
    \end{minipage}
    \begin{minipage}{0.3\linewidth}
    \includegraphics[width=\linewidth]{TMWDL-TSNE-30.png}
    \end{minipage}
    \captionof{figure}{T-SNE embeddings ottenuti con \textbf{Triplet Margin with Distance Loss} dopo: 0, 15, 30 epoche di training}    
\end{center}

\begin{center}
    \begin{minipage}{0.45\linewidth}
    \includegraphics[width=\linewidth]{train_loss_1.png}
    \end{minipage}
    \begin{minipage}{0.45\linewidth}
    \includegraphics[width=\linewidth]{valid_loss_1.png}
    \end{minipage}
    \captionof{figure}{Grafici di convergenza di training (sx) e validation (dx) con Triplet Margin Loss (arancione / blu) e Triplet Margin with Distance Loss (rosso / azzurro)}
\end{center}


\pagebreak
\section{Conclusione}

Dopo 30 epoche si è deciso di procedere continuando il training con la \textbf{Triplet Margin Loss}, in quanto, quest'ultima 
sembrerebbe convergere più rapidamente rispetto all'altra variante. Si ricorda che 
ogni 15 epoche le triplette utilizzate per effettuare l'addestramento sono state cambiate. 

\begin{center}
    \begin{minipage}{0.45\linewidth}
    \includegraphics[width=\linewidth]{train_loss_2.png}
    \end{minipage}
    \begin{minipage}{0.45\linewidth}
    \includegraphics[width=\linewidth]{valid_loss_2.png}
    \end{minipage}
    \captionof{figure}{Grafico di convergenza di training (sx) e validation (dx)}
\end{center}

\begin{center}
    \begin{minipage}{0.3\linewidth}
    \includegraphics[width=\linewidth]{TML-TSNE-0.png}
    \end{minipage}
    \begin{minipage}{0.3\linewidth}
    \includegraphics[width=\linewidth]{TML-TSNE-15.png}
    \end{minipage}
    \begin{minipage}{0.3\linewidth}
    \includegraphics[width=\linewidth]{TML-TSNE-30.png}
    \end{minipage}
    \begin{minipage}{0.3\linewidth}
    \includegraphics[width=\linewidth]{TML-TSNE-45.png}
    \end{minipage}
    \begin{minipage}{0.3\linewidth}
    \includegraphics[width=\linewidth]{TML-TSNE-60.png}
    \end{minipage}
    \captionof{figure}{T-SNE embeddings dopo: 0, 15, 30, 40, 60 epoche di training}
\end{center}

L'errore finale di classificazione ottenuto dopo \texttt{60 epoche} è \texttt{0.861}, mentre quello di validazione \texttt{1.083}. 


\pagebreak

% \begin{thebibliography}{4}

% \bibitem{1} \href{https://pytorch.org/vision/stable/models.html}{Models and Pre-trained Weights}
% \bibitem{2} \href{
%     https://pytorch.org/docs/stable/generated/torch.nn.TripletMarginLoss.html
% }{Triplet Margin Loss}
% \bibitem{2} \href{
%     https://pytorch.org/docs/stable/generated/torch.nn.TripletMarginWithDistanceLoss.html#torch.nn.TripletMarginWithDistanceLoss
% }{Triplet Margin With Distance Loss}
% \bibitem{4} \href{
%     https://pytorch.org/docs/stable/generated/torch.nn.PairwiseDistance.html
% }{PairwiseDistance}

% https://openaccess.thecvf.com/content_CVPR_2020/papers/Ko_Embedding_Expansion_Augmentation_in_Embedding_Space_for_Deep_Metric_Learning_CVPR_2020_paper.pdf

% \end{thebibliography}


\pagebreak
%--/Paper--

\end{document}
