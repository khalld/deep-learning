{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from libs.code import *\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import faiss\n",
    "\n",
    "from libs.Dataset import *\n",
    "from libs.util import *\n",
    "from libs.SiameseNetwork import TripletNetworkTask\n",
    "# non necessari !\n",
    "# from libs.code import *\n",
    "# from libs.VAE import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imposto i seed e le variabili globali:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "random.seed(1996)\n",
    "np.random.seed(1996)\n",
    "pl.seed_everything(1996)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.determinstic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DST = 'dataset/all_labels.csv'\n",
    "PATH_GDRIVE = ''\n",
    "# TODO: se setto > 0 mi da \n",
    "# [W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
    "# e non mi permette di effettuare il training. tuttavia resta troppo lento. come procedo?\n",
    "NUM_WORKERS = 0\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 10\n",
    "GPUS = 0\n",
    "PRETRAINED_MODEL_PATH =  'models/squeezeNet_pretrained.pth'\n",
    "num_class = 3\n",
    "\n",
    "# valori pretrained\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carico il dataset singolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transf = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor(), transforms.Normalize(mean=mean, std=std)])\n",
    "\n",
    "dst = TrashbinDataset(csv=PATH_DST, transform=transf)\n",
    "\n",
    "dst_train, dst_test = split_into_train_and_test(dst)\n",
    "\n",
    "dst_train_loader = DataLoader(dst_train, num_workers=NUM_WORKERS, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dst_test_loader = DataLoader(dst_test, num_workers=NUM_WORKERS, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estraggo le rappresentazioni rgb dai loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 330/330 [05:59<00:00,  1.09s/it]\n",
      "100%|██████████| 83/83 [01:27<00:00,  1.06s/it]\n"
     ]
    }
   ],
   "source": [
    "dst_train_rep_rgb, dst_train_labels = extract_rgb_representations(loader=dst_train_loader)\n",
    "dst_test_rep_rgb, dst_test_labels = extract_rgb_representations(loader=dst_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rappresentazioni di training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10560, 150528)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst_train_rep_rgb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ottengo le predizioni sul test-set usando `predict_nn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample di label: [2 0 0 ... 0 2 2]\n"
     ]
    }
   ],
   "source": [
    "pred_test_label_rgb = predict_nn(dst_train_rep_rgb, dst_test_rep_rgb, dst_train_labels)\n",
    "print(f\"Sample di label: {pred_test_label_rgb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valuto le performance della baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification error: 5.29\n"
     ]
    }
   ],
   "source": [
    "classification_error = evaluate_classification(pred_test_label_rgb, dst_test_labels)\n",
    "print(f\"Classification error: {classification_error:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<s>Importo per effettuare il training della triplenet il miglior modello trovato nella precedente relazione: `SqueezeNet v1.0`. Importo dunque i pesi già trovati dopo il training di 100 epoche .... <b>TODO migliora la descrizione</b> ... importo i pesi.. faccio le opportune modifiche ...</s>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/danilo/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Vorrei usare il modello già allenato precedentemente. Ma come?\n",
    "# scarico il modello da pytorch\n",
    "squeezeNet_1_0 = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_0', pretrained=True)\n",
    "# applico le opportune modifiche\n",
    "squeezeNet_1_0.classifier[1] = nn.Conv2d(512, num_class, kernel_size=(1,1), stride=(1,1))\n",
    "# # # carico i pesi salvati\n",
    "\n",
    "squeezeNet_1_0.load_state_dict(torch.load(PRETRAINED_MODEL_PATH))\n",
    "\n",
    "# testo così\n",
    "squeezeNet_1_0.classifier = nn.Sequential(\n",
    "    # nn.Dropout(p=0.5, inplace=False),\n",
    "    # nn.Conv2d(512, num_class, kernel_size=(1, 1), stride=(1, 1)),\n",
    "    # nn.Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.AdaptiveAvgPool2d(output_size=(1, 1)),\n",
    "    nn.Identity()\n",
    "  )\n",
    "\n",
    "squeezeNet_1_0(torch.zeros(1, 3, 224,224)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 330/330 [12:41<00:00,  2.31s/it]\n",
      "100%|██████████| 83/83 [03:12<00:00,  2.31s/it]\n"
     ]
    }
   ],
   "source": [
    "# uso il modello, allenato nel precedente progetto, per estrarre le rappresentazioni dal training e dal test set\n",
    "dst_train_rep, dst_train_labels = extract_rep_squeezeNet(squeezeNet_1_0, dst_train_loader)\n",
    "dst_test_rep, dst_test_labels = extract_rep_squeezeNet(squeezeNet_1_0, dst_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valuto le performance del sistema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification error: 0.0\n"
     ]
    }
   ],
   "source": [
    "# valuto le performance del sistema con rappresentazioni non ancora ottimizzate\n",
    "pred_test_label = predict_nn(dst_train_rep, dst_test_rep, dst_train_labels)\n",
    "classification_error = evaluate_classification(pred_test_label, dst_test_labels)\n",
    "print(f\"Classification error: {classification_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carico il dataset in triplette:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_triplet = TripletTrashbin(root=PATH_DST, transform=transf)\n",
    "\n",
    "dst_train_triplet, dst_test_triplet = split_into_train_and_test(dst_triplet)\n",
    "\n",
    "triplet_dataset_train_loader = DataLoader(dst_train_triplet, num_workers=NUM_WORKERS, batch_size=BATCH_SIZE, shuffle=True)\n",
    "triplet_dataset_test_loader = DataLoader(dst_test_triplet, num_workers=NUM_WORKERS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: mostra le immagini delle triplette"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alleno la rete con lr=0.002 che è il migliore trovato per SqueezeNet nel precedente progetto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletNetworkTaskDebugged(pl.LightningModule):\n",
    "    # lr uguale a quello del progetto vecchio\n",
    "    def __init__(self, embedding_net, lr=0.002, momentum=0.99, margin=2, num_class=3):\n",
    "        super(TripletNetworkTaskDebugged, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.embedding_net = embedding_net\n",
    "        self.criterion = nn.TripletMarginLoss(margin=margin)\n",
    "        self.num_class = num_class\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return SGD(self.embedding_net.parameters(), self.hparams.lr, momentum=self.hparams.momentum)\n",
    "\n",
    "    # Lightning automatically sets the model to training for training_step and to eval for validation.\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        # print(\"STEP 0: \")\n",
    "\n",
    "        I_i, I_j, I_k, *_ = batch\n",
    "\n",
    "        # print(f\"i_i: {len(I_i)}, i_j :{len(I_j)}, i_k:{len(I_k)}\")\n",
    "\n",
    "        # print(f\"Shape: {I_i.shape}\")\n",
    "\n",
    "        phi_i = self.embedding_net(I_i)\n",
    "        phi_j = self.embedding_net(I_j)\n",
    "        phi_k = self.embedding_net(I_k)\n",
    "\n",
    "        # print(f\"phi_i: {phi_i}, phi_j :{phi_j}, phi_k:{phi_k}\")\n",
    "\n",
    "        # calcoliamo la loss\n",
    "        loss_triplet = self.criterion(phi_i, phi_j, phi_k)\n",
    "        # print(f\"training_step: loss_triplet {loss_triplet}\")\n",
    "        # self.log('train/loss', loss_triplet)\n",
    "        # return loss_triplet\n",
    "        \n",
    "        loss_embedd = phi_i.norm(2) + phi_i.norm(2) + phi_i.norm(2)\n",
    "\n",
    "        print(f\"loss embedd {loss_embedd}\")\n",
    "\n",
    "        loss = loss_triplet + 0.001 *loss_embedd\n",
    "        \n",
    "        print(f\"loss {loss}\")\n",
    "\n",
    "        self.log('train/loss', loss)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        I_i, I_j, I_k, *_ = batch\n",
    "        phi_i = self.embedding_net(I_i)\n",
    "        phi_j = self.embedding_net(I_j)\n",
    "        phi_k = self.embedding_net(I_k)\n",
    "\n",
    "        #calcolo la loss\n",
    "        loss_triplet = self.criterion(phi_i, phi_j, phi_k)\n",
    "        # print(f\"validation_step: loss_triplet {loss_triplet}\")\n",
    "        # self.log('train/loss', loss_triplet)\n",
    "        # return loss_triplet\n",
    "        loss_embedd = phi_i.norm(2) + phi_i.norm(2) + phi_i.norm(2)\n",
    "        loss = loss_triplet + 0.001 * loss_embedd\n",
    "\n",
    "        self.log('valid/loss', loss)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name          | Type              | Params\n",
      "----------------------------------------------------\n",
      "0 | embedding_net | SqueezeNet        | 735 K \n",
      "1 | criterion     | TripletMarginLoss | 0     \n",
      "----------------------------------------------------\n",
      "735 K     Trainable params\n",
      "0         Non-trainable params\n",
      "735 K     Total params\n",
      "2.942     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danilo/GitHub/deep-learning/venv/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:117: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1996\n",
      "/Users/danilo/GitHub/deep-learning/venv/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:117: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/330 [00:00<?, ?it/s] loss embedd 1367.348876953125\n",
      "loss 5.100234031677246\n",
      "Epoch 0:   0%|          | 1/330 [00:14<1:21:20, 14.83s/it, loss=5.1, v_num=0]loss embedd 1074.210205078125\n",
      "loss 7.562237739562988\n",
      "Epoch 0:   1%|          | 2/330 [00:26<1:13:14, 13.40s/it, loss=6.33, v_num=0]loss embedd 600.2630615234375\n",
      "loss 4.470737457275391\n",
      "Epoch 0:   1%|          | 3/330 [00:38<1:10:31, 12.94s/it, loss=5.71, v_num=0]loss embedd 310.4503479003906\n",
      "loss 1.7181496620178223\n",
      "Epoch 0:   1%|          | 4/330 [00:50<1:08:49, 12.67s/it, loss=4.71, v_num=0]loss embedd 251.20335388183594\n",
      "loss 2.1942408084869385\n",
      "Epoch 0:   2%|▏         | 5/330 [01:02<1:07:47, 12.51s/it, loss=4.21, v_num=0]loss embedd 83.70124816894531\n",
      "loss 1.7673686742782593\n",
      "Epoch 0:   2%|▏         | 6/330 [01:14<1:06:58, 12.40s/it, loss=3.8, v_num=0] loss embedd 120.61901092529297\n",
      "loss 1.583471655845642\n",
      "Epoch 0:   2%|▏         | 7/330 [01:26<1:06:20, 12.32s/it, loss=3.49, v_num=0]loss embedd 149.26229858398438\n",
      "loss 2.077422618865967\n",
      "Epoch 0:   2%|▏         | 8/330 [01:38<1:05:48, 12.26s/it, loss=3.31, v_num=0]loss embedd 167.22457885742188\n",
      "loss 1.7637739181518555\n",
      "Epoch 0:   3%|▎         | 9/330 [01:49<1:05:21, 12.22s/it, loss=3.14, v_num=0]loss embedd 175.24383544921875\n",
      "loss 1.8300983905792236\n",
      "Epoch 0:   3%|▎         | 10/330 [02:01<1:04:57, 12.18s/it, loss=3.01, v_num=0]loss embedd 151.39675903320312\n",
      "loss 1.5973196029663086\n",
      "Epoch 0:   3%|▎         | 11/330 [02:13<1:04:36, 12.15s/it, loss=2.88, v_num=0]loss embedd 476.83624267578125\n",
      "loss 3.671830177307129\n",
      "Epoch 0:   4%|▎         | 12/330 [02:25<1:04:17, 12.13s/it, loss=2.94, v_num=0]loss embedd 66.21818542480469\n",
      "loss 1.4619901180267334\n",
      "Epoch 0:   4%|▍         | 13/330 [02:37<1:04:01, 12.12s/it, loss=2.83, v_num=0]loss embedd 70.66458129882812\n",
      "loss 1.6221823692321777\n",
      "Epoch 0:   4%|▍         | 14/330 [02:49<1:03:43, 12.10s/it, loss=2.74, v_num=0]loss embedd 278.074462890625\n",
      "loss 2.072827100753784\n",
      "Epoch 0:   5%|▍         | 15/330 [03:01<1:03:25, 12.08s/it, loss=2.7, v_num=0] loss embedd 112.04486083984375\n",
      "loss 1.0902588367462158\n",
      "Epoch 0:   5%|▍         | 16/330 [03:13<1:03:09, 12.07s/it, loss=2.6, v_num=0]loss embedd 170.8192138671875\n",
      "loss 1.6556098461151123\n",
      "Epoch 0:   5%|▌         | 17/330 [03:24<1:02:54, 12.06s/it, loss=2.54, v_num=0]loss embedd 285.6882629394531\n",
      "loss 1.2675223350524902\n",
      "Epoch 0:   5%|▌         | 18/330 [03:36<1:02:39, 12.05s/it, loss=2.47, v_num=0]loss embedd 417.8196716308594\n",
      "loss 1.7682945728302002\n",
      "Epoch 0:   6%|▌         | 19/330 [03:48<1:02:24, 12.04s/it, loss=2.44, v_num=0]loss embedd 193.5364990234375\n",
      "loss 1.7850897312164307\n",
      "Epoch 0:   6%|▌         | 20/330 [04:00<1:02:08, 12.03s/it, loss=2.4, v_num=0] loss embedd 200.1656494140625\n",
      "loss 1.3742552995681763\n",
      "Epoch 0:   6%|▋         | 21/330 [04:12<1:01:54, 12.02s/it, loss=2.22, v_num=0]loss embedd 660.718994140625\n",
      "loss 2.25809383392334\n",
      "Epoch 0:   7%|▋         | 22/330 [04:24<1:01:39, 12.01s/it, loss=1.95, v_num=0]loss embedd 769.021728515625\n",
      "loss 3.417618989944458\n",
      "Epoch 0:   7%|▋         | 23/330 [04:36<1:01:26, 12.01s/it, loss=1.9, v_num=0] loss embedd 223.0194091796875\n",
      "loss 1.4576339721679688\n",
      "Epoch 0:   7%|▋         | 24/330 [04:48<1:01:13, 12.00s/it, loss=1.89, v_num=0]loss embedd 144.51565551757812\n",
      "loss 1.8831983804702759\n",
      "Epoch 0:   8%|▊         | 25/330 [05:00<1:01:01, 12.00s/it, loss=1.87, v_num=0]loss embedd 80.21161651611328\n",
      "loss 2.0539629459381104\n",
      "Epoch 0:   8%|▊         | 26/330 [05:11<1:00:47, 12.00s/it, loss=1.88, v_num=0]loss embedd 370.67510986328125\n",
      "loss 2.3864402770996094\n",
      "Epoch 0:   8%|▊         | 27/330 [05:23<1:00:34, 12.00s/it, loss=1.92, v_num=0]loss embedd 201.5914306640625\n",
      "loss 1.9047434329986572\n",
      "Epoch 0:   8%|▊         | 28/330 [05:35<1:00:22, 11.99s/it, loss=1.92, v_num=0]loss embedd 0.16363279521465302\n",
      "loss 1.9998584985733032\n",
      "Epoch 0:   9%|▉         | 29/330 [05:47<1:00:08, 11.99s/it, loss=1.93, v_num=0]loss embedd 0.0\n",
      "loss 2.0006394386291504\n",
      "Epoch 0:   9%|▉         | 30/330 [05:59<59:56, 11.99s/it, loss=1.94, v_num=0]  loss embedd 0.03218718245625496\n",
      "loss 1.998746395111084\n",
      "Epoch 0:   9%|▉         | 31/330 [06:11<59:43, 11.98s/it, loss=1.96, v_num=0]loss embedd 0.40249478816986084\n",
      "loss 2.002530097961426\n",
      "Epoch 0:  10%|▉         | 32/330 [06:23<59:32, 11.99s/it, loss=1.87, v_num=0]loss embedd 0.8753666877746582\n",
      "loss 2.003772497177124\n",
      "Epoch 0:  10%|█         | 33/330 [06:35<59:18, 11.98s/it, loss=1.9, v_num=0] loss embedd 2.225097179412842\n",
      "loss 1.9987655878067017\n",
      "Epoch 0:  10%|█         | 34/330 [06:47<59:05, 11.98s/it, loss=1.92, v_num=0]loss embedd 3.8537755012512207\n",
      "loss 1.9591938257217407\n",
      "Epoch 0:  11%|█         | 35/330 [06:59<58:53, 11.98s/it, loss=1.91, v_num=0]loss embedd 28.87201690673828\n",
      "loss 1.9874463081359863\n",
      "Epoch 0:  11%|█         | 36/330 [07:11<58:42, 11.98s/it, loss=1.96, v_num=0]loss embedd 94.15255737304688\n",
      "loss 2.4843859672546387\n",
      "Epoch 0:  11%|█         | 37/330 [07:23<58:29, 11.98s/it, loss=2, v_num=0]   loss embedd 92.36056518554688\n",
      "loss 2.211923837661743\n",
      "Epoch 0:  12%|█▏        | 38/330 [07:35<58:16, 11.98s/it, loss=2.05, v_num=0]loss embedd 48.67395782470703\n",
      "loss 2.1144022941589355\n",
      "Epoch 0:  12%|█▏        | 39/330 [07:46<58:03, 11.97s/it, loss=2.06, v_num=0]loss embedd 66.15771484375\n",
      "loss 1.9426299333572388\n",
      "Epoch 0:  12%|█▏        | 40/330 [07:58<57:50, 11.97s/it, loss=2.07, v_num=0]loss embedd 1204.2825927734375\n",
      "loss 6.062070369720459\n",
      "Epoch 0:  12%|█▏        | 41/330 [08:10<57:38, 11.97s/it, loss=2.31, v_num=0]loss embedd 49.15931701660156\n",
      "loss 2.0388834476470947\n",
      "Epoch 0:  13%|█▎        | 42/330 [08:22<57:25, 11.96s/it, loss=2.3, v_num=0] loss embedd 27.436508178710938\n",
      "loss 2.0248982906341553\n",
      "Epoch 0:  13%|█▎        | 43/330 [08:34<57:12, 11.96s/it, loss=2.23, v_num=0]loss embedd 17.70258903503418\n",
      "loss 2.0552804470062256\n",
      "Epoch 0:  13%|█▎        | 44/330 [08:46<57:00, 11.96s/it, loss=2.26, v_num=0]loss embedd 7.75984525680542\n",
      "loss 2.040187120437622\n",
      "Epoch 0:  14%|█▎        | 45/330 [08:58<56:47, 11.96s/it, loss=2.26, v_num=0]loss embedd 1.7588272094726562\n",
      "loss 1.9941997528076172\n",
      "Epoch 0:  14%|█▍        | 46/330 [09:09<56:35, 11.96s/it, loss=2.26, v_num=0]loss embedd 8.204137802124023\n",
      "loss 1.999087929725647\n",
      "Epoch 0:  14%|█▍        | 47/330 [09:21<56:23, 11.96s/it, loss=2.24, v_num=0]loss embedd 119.82563781738281\n",
      "loss 1.741152048110962\n",
      "Epoch 0:  15%|█▍        | 48/330 [09:33<56:11, 11.95s/it, loss=2.23, v_num=0]loss embedd 843.8638916015625\n",
      "loss 4.133265495300293\n",
      "Epoch 0:  15%|█▍        | 49/330 [09:45<55:58, 11.95s/it, loss=2.34, v_num=0]loss embedd 283.58056640625\n",
      "loss 2.4820210933685303\n",
      "Epoch 0:  15%|█▌        | 50/330 [09:57<55:46, 11.95s/it, loss=2.36, v_num=0]loss embedd 70.3977279663086\n",
      "loss 1.9825457334518433\n",
      "Epoch 0:  15%|█▌        | 51/330 [10:09<55:33, 11.95s/it, loss=2.36, v_num=0]loss embedd 421.8494567871094\n",
      "loss 2.4685091972351074\n",
      "Epoch 0:  16%|█▌        | 52/330 [10:21<55:20, 11.95s/it, loss=2.39, v_num=0]loss embedd 189.62399291992188\n",
      "loss 2.3740851879119873\n",
      "Epoch 0:  16%|█▌        | 53/330 [10:33<55:08, 11.94s/it, loss=2.4, v_num=0] loss embedd 100.93211364746094\n",
      "loss 1.8890749216079712\n",
      "Epoch 0:  16%|█▋        | 54/330 [10:44<54:55, 11.94s/it, loss=2.4, v_num=0]loss embedd 99.56426239013672\n",
      "loss 1.5137051343917847\n",
      "Epoch 0:  17%|█▋        | 55/330 [10:56<54:43, 11.94s/it, loss=2.38, v_num=0]loss embedd 175.30560302734375\n",
      "loss 1.8413444757461548\n",
      "Epoch 0:  17%|█▋        | 56/330 [11:08<54:31, 11.94s/it, loss=2.37, v_num=0]loss embedd 193.30650329589844\n",
      "loss 1.906653642654419\n",
      "Epoch 0:  17%|█▋        | 57/330 [11:20<54:19, 11.94s/it, loss=2.34, v_num=0]loss embedd 184.315185546875\n",
      "loss 2.0241620540618896\n",
      "Epoch 0:  18%|█▊        | 58/330 [11:32<54:07, 11.94s/it, loss=2.33, v_num=0]loss embedd 120.2541275024414\n",
      "loss 1.6696958541870117\n",
      "Epoch 0:  18%|█▊        | 59/330 [11:44<53:54, 11.94s/it, loss=2.31, v_num=0]loss embedd 73.10346221923828\n",
      "loss 1.777387022972107\n",
      "Epoch 0:  18%|█▊        | 60/330 [11:56<53:42, 11.94s/it, loss=2.3, v_num=0] loss embedd 89.65846252441406\n",
      "loss 1.8441678285598755\n",
      "Epoch 0:  18%|█▊        | 61/330 [12:07<53:30, 11.93s/it, loss=2.09, v_num=0]loss embedd 116.3137435913086\n",
      "loss 1.6960387229919434\n",
      "Epoch 0:  19%|█▉        | 62/330 [12:19<53:17, 11.93s/it, loss=2.07, v_num=0]loss embedd 157.56874084472656\n",
      "loss 2.163642168045044\n",
      "Epoch 0:  19%|█▉        | 63/330 [12:31<53:06, 11.93s/it, loss=2.08, v_num=0]loss embedd 119.51591491699219\n",
      "loss 1.6966346502304077\n",
      "Epoch 0:  19%|█▉        | 64/330 [12:43<52:53, 11.93s/it, loss=2.06, v_num=0]loss embedd 111.59103393554688\n",
      "loss 1.330174207687378\n",
      "Epoch 0:  20%|█▉        | 65/330 [12:55<52:41, 11.93s/it, loss=2.03, v_num=0]loss embedd 169.39329528808594\n",
      "loss 1.7224204540252686\n",
      "Epoch 0:  20%|██        | 66/330 [13:07<52:29, 11.93s/it, loss=2.01, v_num=0]loss embedd 195.55508422851562\n",
      "loss 2.168231964111328\n",
      "Epoch 0:  20%|██        | 67/330 [13:19<52:17, 11.93s/it, loss=2.02, v_num=0]loss embedd 149.0304718017578\n",
      "loss 2.2143771648406982\n",
      "Epoch 0:  21%|██        | 68/330 [13:31<52:05, 11.93s/it, loss=2.04, v_num=0]loss embedd 50.956546783447266\n",
      "loss 1.9924077987670898\n",
      "Epoch 0:  21%|██        | 69/330 [13:43<51:53, 11.93s/it, loss=1.94, v_num=0]loss embedd 12.175264358520508\n",
      "loss 2.0095601081848145\n",
      "Epoch 0:  21%|██        | 70/330 [13:54<51:40, 11.93s/it, loss=1.91, v_num=0]loss embedd 46.93100357055664\n",
      "loss 1.8036013841629028\n",
      "Epoch 0:  22%|██▏       | 71/330 [14:06<51:28, 11.93s/it, loss=1.91, v_num=0]loss embedd 176.890625\n",
      "loss 1.3829517364501953\n",
      "Epoch 0:  22%|██▏       | 72/330 [14:18<51:16, 11.92s/it, loss=1.85, v_num=0]loss embedd 317.1493225097656\n",
      "loss 2.1871469020843506\n",
      "Epoch 0:  22%|██▏       | 73/330 [14:30<51:04, 11.92s/it, loss=1.84, v_num=0]loss embedd 332.91424560546875\n",
      "loss 2.2353241443634033\n",
      "Epoch 0:  22%|██▏       | 74/330 [14:42<50:52, 11.92s/it, loss=1.86, v_num=0]loss embedd 282.2831726074219\n",
      "loss 1.5561290979385376\n",
      "Epoch 0:  23%|██▎       | 75/330 [14:54<50:40, 11.92s/it, loss=1.86, v_num=0]loss embedd 194.91281127929688\n",
      "loss 1.9567197561264038\n",
      "Epoch 0:  23%|██▎       | 76/330 [15:06<50:28, 11.92s/it, loss=1.87, v_num=0]loss embedd 122.35221862792969\n",
      "loss 1.9415184259414673\n",
      "Epoch 0:  23%|██▎       | 77/330 [15:17<50:16, 11.92s/it, loss=1.87, v_num=0]loss embedd 104.670166015625\n",
      "loss 1.757487177848816\n",
      "Epoch 0:  24%|██▎       | 78/330 [15:29<50:03, 11.92s/it, loss=1.86, v_num=0]loss embedd 125.54618835449219\n",
      "loss 1.5204921960830688\n",
      "Epoch 0:  24%|██▍       | 79/330 [15:41<49:51, 11.92s/it, loss=1.85, v_num=0]loss embedd 193.06198120117188\n",
      "loss 1.9575923681259155\n",
      "Epoch 0:  24%|██▍       | 80/330 [15:53<49:39, 11.92s/it, loss=1.86, v_num=0]loss embedd 207.53306579589844\n",
      "loss 1.5825012922286987\n",
      "Epoch 0:  25%|██▍       | 81/330 [16:05<49:27, 11.92s/it, loss=1.84, v_num=0]loss embedd 180.30938720703125\n",
      "loss 1.1413873434066772\n",
      "Epoch 0:  25%|██▍       | 82/330 [16:17<49:15, 11.92s/it, loss=1.82, v_num=0]loss embedd 204.24807739257812\n",
      "loss 1.4430004358291626\n",
      "Epoch 0:  25%|██▌       | 83/330 [16:29<49:03, 11.92s/it, loss=1.78, v_num=0]loss embedd 220.2329864501953\n",
      "loss 1.7544879913330078\n",
      "Epoch 0:  25%|██▌       | 84/330 [16:40<48:51, 11.92s/it, loss=1.78, v_num=0]loss embedd 223.78111267089844\n",
      "loss 1.417367935180664\n",
      "Epoch 0:  26%|██▌       | 85/330 [16:52<48:39, 11.92s/it, loss=1.79, v_num=0]loss embedd 226.48712158203125\n",
      "loss 1.705809235572815\n",
      "Epoch 0:  26%|██▌       | 86/330 [17:04<48:27, 11.92s/it, loss=1.79, v_num=0]loss embedd 191.98468017578125\n",
      "loss 1.5307639837265015\n",
      "Epoch 0:  26%|██▋       | 87/330 [17:16<48:15, 11.92s/it, loss=1.75, v_num=0]loss embedd 162.79730224609375\n",
      "loss 1.6228432655334473\n",
      "Epoch 0:  27%|██▋       | 88/330 [17:28<48:03, 11.92s/it, loss=1.72, v_num=0]loss embedd 116.44296264648438\n",
      "loss 1.586182951927185\n",
      "Epoch 0:  27%|██▋       | 89/330 [17:40<47:51, 11.92s/it, loss=1.7, v_num=0] loss embedd 76.66339111328125\n",
      "loss 1.5280070304870605\n",
      "Epoch 0:  27%|██▋       | 90/330 [17:52<47:39, 11.92s/it, loss=1.68, v_num=0]loss embedd 54.65057373046875\n",
      "loss 1.7353956699371338\n",
      "Epoch 0:  28%|██▊       | 91/330 [18:04<47:27, 11.92s/it, loss=1.68, v_num=0]loss embedd 45.77611541748047\n",
      "loss 1.8030027151107788\n",
      "Epoch 0:  28%|██▊       | 92/330 [18:16<47:16, 11.92s/it, loss=1.7, v_num=0] loss embedd 58.7483024597168\n",
      "loss 1.8875377178192139\n",
      "Epoch 0:  28%|██▊       | 93/330 [18:28<47:04, 11.92s/it, loss=1.68, v_num=0]loss embedd 107.58483123779297\n",
      "loss 1.5107029676437378\n",
      "Epoch 0:  28%|██▊       | 94/330 [18:40<46:52, 11.92s/it, loss=1.65, v_num=0]loss embedd 151.98532104492188\n",
      "loss 2.19756817817688\n",
      "Epoch 0:  29%|██▉       | 95/330 [18:52<46:40, 11.92s/it, loss=1.68, v_num=0]loss embedd 50.84732437133789\n",
      "loss 1.7040069103240967\n",
      "Epoch 0:  29%|██▉       | 96/330 [19:03<46:28, 11.92s/it, loss=1.67, v_num=0]loss embedd 60.318626403808594\n",
      "loss 1.749106526374817\n",
      "Epoch 0:  29%|██▉       | 97/330 [19:15<46:16, 11.91s/it, loss=1.66, v_num=0]loss embedd 120.07313537597656\n",
      "loss 1.4139113426208496\n",
      "Epoch 0:  30%|██▉       | 98/330 [19:27<46:04, 11.91s/it, loss=1.64, v_num=0]loss embedd 175.57000732421875\n",
      "loss 1.5969278812408447\n",
      "Epoch 0:  30%|███       | 99/330 [19:39<45:52, 11.91s/it, loss=1.64, v_num=0]loss embedd 138.35134887695312\n",
      "loss 1.3082847595214844\n",
      "Epoch 0:  30%|███       | 100/330 [19:51<45:40, 11.91s/it, loss=1.61, v_num=0]loss embedd 141.7586669921875\n",
      "loss 1.9688379764556885\n",
      "Epoch 0:  31%|███       | 101/330 [20:03<45:28, 11.91s/it, loss=1.63, v_num=0]loss embedd 123.05751037597656\n",
      "loss 1.5345213413238525\n",
      "Epoch 0:  31%|███       | 102/330 [20:15<45:16, 11.91s/it, loss=1.65, v_num=0]loss embedd 115.03532409667969\n",
      "loss 1.7298094034194946\n",
      "Epoch 0:  31%|███       | 103/330 [20:27<45:04, 11.91s/it, loss=1.66, v_num=0]loss embedd 131.08447265625\n",
      "loss 1.6116752624511719\n",
      "Epoch 0:  32%|███▏      | 104/330 [20:38<44:52, 11.91s/it, loss=1.66, v_num=0]loss embedd 121.3656234741211\n",
      "loss 1.646033525466919\n",
      "Epoch 0:  32%|███▏      | 105/330 [20:50<44:40, 11.91s/it, loss=1.67, v_num=0]loss embedd 137.05697631835938\n",
      "loss 1.5565662384033203\n",
      "Epoch 0:  32%|███▏      | 106/330 [21:02<44:28, 11.91s/it, loss=1.66, v_num=0]loss embedd 161.59576416015625\n",
      "loss 1.873709797859192\n",
      "Epoch 0:  32%|███▏      | 107/330 [21:14<44:16, 11.91s/it, loss=1.68, v_num=0]loss embedd 165.1962127685547\n",
      "loss 1.6939862966537476\n",
      "Epoch 0:  33%|███▎      | 108/330 [21:26<44:04, 11.91s/it, loss=1.68, v_num=0]loss embedd 154.70518493652344\n",
      "loss 1.8104803562164307\n",
      "Epoch 0:  33%|███▎      | 109/330 [21:38<43:52, 11.91s/it, loss=1.69, v_num=0]loss embedd 158.0032958984375\n",
      "loss 1.7432420253753662\n",
      "Epoch 0:  33%|███▎      | 110/330 [21:50<43:40, 11.91s/it, loss=1.7, v_num=0] loss embedd 149.13027954101562\n",
      "loss 1.746422290802002\n",
      "Epoch 0:  34%|███▎      | 111/330 [22:02<43:28, 11.91s/it, loss=1.7, v_num=0]loss embedd 129.203125\n",
      "loss 1.3134050369262695\n",
      "Epoch 0:  34%|███▍      | 112/330 [22:13<43:16, 11.91s/it, loss=1.68, v_num=0]loss embedd 148.86599731445312\n",
      "loss 1.7519168853759766\n",
      "Epoch 0:  34%|███▍      | 113/330 [22:25<43:04, 11.91s/it, loss=1.67, v_num=0]loss embedd 130.14877319335938\n",
      "loss 1.6488527059555054\n",
      "Epoch 0:  35%|███▍      | 114/330 [22:37<42:52, 11.91s/it, loss=1.68, v_num=0]loss embedd 140.5072021484375\n",
      "loss 1.590269684791565\n",
      "Epoch 0:  35%|███▍      | 115/330 [22:49<42:40, 11.91s/it, loss=1.65, v_num=0]loss embedd 139.55572509765625\n",
      "loss 1.5472244024276733\n",
      "Epoch 0:  35%|███▌      | 116/330 [23:01<42:28, 11.91s/it, loss=1.64, v_num=0]loss embedd 169.3275146484375\n",
      "loss 2.2513654232025146\n",
      "Epoch 0:  35%|███▌      | 117/330 [23:13<42:16, 11.91s/it, loss=1.67, v_num=0]loss embedd 80.46768188476562\n",
      "loss 1.6032373905181885\n",
      "Epoch 0:  36%|███▌      | 118/330 [23:25<42:04, 11.91s/it, loss=1.68, v_num=0]loss embedd 264.0797119140625\n",
      "loss 2.5770018100738525\n",
      "Epoch 0:  36%|███▌      | 119/330 [23:37<41:53, 11.91s/it, loss=1.73, v_num=0]loss embedd 68.87525177001953\n",
      "loss 1.7091352939605713\n",
      "Epoch 0:  36%|███▋      | 120/330 [23:49<41:41, 11.91s/it, loss=1.75, v_num=0]loss embedd 116.74824523925781\n",
      "loss 1.6833534240722656\n",
      "Epoch 0:  37%|███▋      | 121/330 [24:01<41:29, 11.91s/it, loss=1.73, v_num=0]loss embedd 108.64677429199219\n",
      "loss 1.5273090600967407\n",
      "Epoch 0:  37%|███▋      | 122/330 [24:12<41:17, 11.91s/it, loss=1.73, v_num=0]loss embedd 134.8706817626953\n",
      "loss 1.946269154548645\n",
      "Epoch 0:  37%|███▋      | 123/330 [24:24<41:05, 11.91s/it, loss=1.74, v_num=0]loss embedd 136.40768432617188\n",
      "loss 1.4925967454910278\n",
      "Epoch 0:  38%|███▊      | 124/330 [24:36<40:53, 11.91s/it, loss=1.74, v_num=0]loss embedd 167.59925842285156\n",
      "loss 1.3237268924713135\n",
      "Epoch 0:  38%|███▊      | 125/330 [24:48<40:41, 11.91s/it, loss=1.72, v_num=0]loss embedd 178.25636291503906\n",
      "loss 1.4549450874328613\n",
      "Epoch 0:  38%|███▊      | 126/330 [25:00<40:29, 11.91s/it, loss=1.71, v_num=0]loss embedd 192.69369506835938\n",
      "loss 2.2204747200012207\n",
      "Epoch 0:  38%|███▊      | 127/330 [25:12<40:17, 11.91s/it, loss=1.73, v_num=0]loss embedd 96.41444396972656\n",
      "loss 1.7473104000091553\n",
      "Epoch 0:  39%|███▉      | 128/330 [25:24<40:05, 11.91s/it, loss=1.73, v_num=0]loss embedd 138.45751953125\n",
      "loss 1.5885121822357178\n",
      "Epoch 0:  39%|███▉      | 129/330 [25:36<39:53, 11.91s/it, loss=1.72, v_num=0]loss embedd 160.28761291503906\n",
      "loss 1.0028879642486572\n",
      "Epoch 0:  39%|███▉      | 130/330 [25:47<39:41, 11.91s/it, loss=1.69, v_num=0]loss embedd 246.4378662109375\n",
      "loss 1.5511118173599243\n",
      "Epoch 0:  40%|███▉      | 131/330 [25:59<39:29, 11.91s/it, loss=1.68, v_num=0]loss embedd 198.58871459960938\n",
      "loss 1.1461091041564941\n",
      "Epoch 0:  40%|████      | 132/330 [26:11<39:17, 11.91s/it, loss=1.67, v_num=0]loss embedd 82.92280578613281\n",
      "loss 1.3673816919326782\n",
      "Epoch 0:  40%|████      | 133/330 [26:23<39:05, 11.91s/it, loss=1.65, v_num=0]loss embedd 244.0641632080078\n",
      "loss 1.1492841243743896\n",
      "Epoch 0:  41%|████      | 134/330 [26:35<38:53, 11.91s/it, loss=1.62, v_num=0]loss embedd 379.49755859375\n",
      "loss 1.8472671508789062\n",
      "Epoch 0:  41%|████      | 135/330 [26:47<38:41, 11.91s/it, loss=1.64, v_num=0]loss embedd 325.90655517578125\n",
      "loss 2.4579570293426514\n",
      "Epoch 0:  41%|████      | 136/330 [26:59<38:29, 11.91s/it, loss=1.68, v_num=0]loss embedd 77.7685546875\n",
      "loss 1.4611763954162598\n",
      "Epoch 0:  42%|████▏     | 137/330 [27:11<38:17, 11.91s/it, loss=1.64, v_num=0]loss embedd 75.29519653320312\n",
      "loss 1.9675592184066772\n",
      "Epoch 0:  42%|████▏     | 138/330 [27:23<38:06, 11.91s/it, loss=1.66, v_num=0]loss embedd 64.75509643554688\n",
      "loss 1.5434025526046753\n",
      "Epoch 0:  42%|████▏     | 139/330 [27:34<37:54, 11.91s/it, loss=1.61, v_num=0]loss embedd 163.41966247558594\n",
      "loss 1.3276729583740234\n",
      "Epoch 0:  42%|████▏     | 140/330 [27:46<37:42, 11.91s/it, loss=1.59, v_num=0]loss embedd 205.95730590820312\n",
      "loss 1.4678069353103638\n",
      "Epoch 0:  43%|████▎     | 141/330 [27:58<37:30, 11.91s/it, loss=1.58, v_num=0]loss embedd 190.08656311035156\n",
      "loss 1.4925843477249146\n",
      "Epoch 0:  43%|████▎     | 142/330 [28:10<37:18, 11.91s/it, loss=1.58, v_num=0]loss embedd 185.06341552734375\n",
      "loss 1.5357024669647217\n",
      "Epoch 0:  43%|████▎     | 143/330 [28:22<37:06, 11.91s/it, loss=1.56, v_num=0]loss embedd 119.11599731445312\n",
      "loss 1.6531058549880981\n",
      "Epoch 0:  44%|████▎     | 144/330 [28:34<36:54, 11.91s/it, loss=1.57, v_num=0]loss embedd 67.87965393066406\n",
      "loss 1.5954186916351318\n",
      "Epoch 0:  44%|████▍     | 145/330 [28:46<36:42, 11.91s/it, loss=1.58, v_num=0]loss embedd 52.25595474243164\n",
      "loss 1.6272120475769043\n",
      "Epoch 0:  44%|████▍     | 146/330 [28:58<36:30, 11.91s/it, loss=1.59, v_num=0]loss embedd 42.86275863647461\n",
      "loss 1.74562668800354\n",
      "Epoch 0:  45%|████▍     | 147/330 [29:10<36:18, 11.91s/it, loss=1.56, v_num=0]loss embedd 47.7646598815918\n",
      "loss 1.5861746072769165\n",
      "Epoch 0:  45%|████▍     | 148/330 [29:22<36:06, 11.91s/it, loss=1.56, v_num=0]loss embedd 67.62564086914062\n",
      "loss 2.0926332473754883\n",
      "Epoch 0:  45%|████▌     | 149/330 [29:33<35:54, 11.91s/it, loss=1.58, v_num=0]loss embedd 79.19466400146484\n",
      "loss 1.643174409866333\n",
      "Epoch 0:  45%|████▌     | 150/330 [29:45<35:42, 11.91s/it, loss=1.61, v_num=0]loss embedd 94.52420043945312\n",
      "loss 1.2677836418151855\n",
      "Epoch 0:  46%|████▌     | 151/330 [29:57<35:31, 11.91s/it, loss=1.6, v_num=0] loss embedd 108.68154907226562\n",
      "loss 1.4562618732452393\n",
      "Epoch 0:  46%|████▌     | 152/330 [30:09<35:19, 11.91s/it, loss=1.61, v_num=0]loss embedd 144.305419921875\n",
      "loss 1.4947067499160767\n",
      "Epoch 0:  46%|████▋     | 153/330 [30:21<35:07, 11.91s/it, loss=1.62, v_num=0]loss embedd 161.28021240234375\n",
      "loss 1.1185634136199951\n",
      "Epoch 0:  47%|████▋     | 154/330 [30:33<34:55, 11.90s/it, loss=1.62, v_num=0]loss embedd 197.9516143798828\n",
      "loss 2.128371000289917\n",
      "Epoch 0:  47%|████▋     | 155/330 [30:45<34:43, 11.91s/it, loss=1.63, v_num=0]loss embedd 219.65419006347656\n",
      "loss 1.7983295917510986\n",
      "Epoch 0:  47%|████▋     | 156/330 [30:57<34:31, 11.91s/it, loss=1.6, v_num=0] loss embedd 168.8232421875\n",
      "loss 1.28091561794281\n",
      "Epoch 0:  48%|████▊     | 157/330 [31:09<34:19, 11.90s/it, loss=1.59, v_num=0]loss embedd 125.57339477539062\n",
      "loss 1.7144814729690552\n",
      "Epoch 0:  48%|████▊     | 158/330 [31:20<34:07, 11.90s/it, loss=1.58, v_num=0]loss embedd 78.91670227050781\n",
      "loss 1.8540078401565552\n",
      "Epoch 0:  48%|████▊     | 159/330 [31:32<33:55, 11.90s/it, loss=1.59, v_num=0]loss embedd 60.29485321044922\n",
      "loss 1.8624392747879028\n",
      "Epoch 0:  48%|████▊     | 160/330 [31:44<33:43, 11.91s/it, loss=1.62, v_num=0]loss embedd 51.62421798706055\n",
      "loss 1.6408076286315918\n",
      "Epoch 0:  49%|████▉     | 161/330 [31:56<33:31, 11.91s/it, loss=1.63, v_num=0]loss embedd 50.803611755371094\n",
      "loss 1.898695945739746\n",
      "Epoch 0:  49%|████▉     | 162/330 [32:08<33:20, 11.90s/it, loss=1.65, v_num=0]loss embedd 45.83201599121094\n",
      "loss 1.960031509399414\n",
      "Epoch 0:  49%|████▉     | 163/330 [32:20<33:08, 11.91s/it, loss=1.67, v_num=0]loss embedd 52.45625305175781\n",
      "loss 1.9381663799285889\n",
      "Epoch 0:  50%|████▉     | 164/330 [32:32<32:56, 11.91s/it, loss=1.69, v_num=0]loss embedd 57.06551742553711\n",
      "loss 1.6052610874176025\n",
      "Epoch 0:  50%|█████     | 165/330 [32:44<32:44, 11.91s/it, loss=1.69, v_num=0]loss embedd 76.10960388183594\n",
      "loss 1.7652407884597778\n",
      "Epoch 0:  50%|█████     | 166/330 [32:56<32:32, 11.91s/it, loss=1.69, v_num=0]loss embedd 81.76374053955078\n",
      "loss 1.7420295476913452\n",
      "Epoch 0:  51%|█████     | 167/330 [33:08<32:20, 11.91s/it, loss=1.69, v_num=0]loss embedd 106.16737365722656\n",
      "loss 1.8782751560211182\n",
      "Epoch 0:  51%|█████     | 168/330 [33:20<32:08, 11.91s/it, loss=1.71, v_num=0]loss embedd 106.7175521850586\n",
      "loss 1.8393657207489014\n",
      "Epoch 0:  51%|█████     | 169/330 [33:32<31:56, 11.91s/it, loss=1.69, v_num=0]loss embedd 100.32215881347656\n",
      "loss 1.909985065460205\n",
      "Epoch 0:  52%|█████▏    | 170/330 [33:43<31:44, 11.91s/it, loss=1.71, v_num=0]loss embedd 93.14954376220703\n",
      "loss 1.6835660934448242\n",
      "Epoch 0:  52%|█████▏    | 171/330 [33:55<31:32, 11.91s/it, loss=1.73, v_num=0]loss embedd 90.36473083496094\n",
      "loss 1.782130241394043\n",
      "Epoch 0:  52%|█████▏    | 172/330 [34:07<31:21, 11.91s/it, loss=1.74, v_num=0]loss embedd 91.06646728515625\n",
      "loss 1.4673014879226685\n",
      "Epoch 0:  52%|█████▏    | 173/330 [34:19<31:09, 11.91s/it, loss=1.74, v_num=0]loss embedd 120.6719741821289\n",
      "loss 2.040371894836426\n",
      "Epoch 0:  53%|█████▎    | 174/330 [34:31<30:57, 11.91s/it, loss=1.79, v_num=0]loss embedd 132.40638732910156\n",
      "loss 1.5310499668121338\n",
      "Epoch 0:  53%|█████▎    | 175/330 [34:43<30:45, 11.91s/it, loss=1.76, v_num=0]loss embedd 141.73541259765625\n",
      "loss 2.287078857421875\n",
      "Epoch 0:  53%|█████▎    | 176/330 [34:55<30:33, 11.91s/it, loss=1.78, v_num=0]loss embedd 134.1573486328125\n",
      "loss 1.5879747867584229\n",
      "Epoch 0:  54%|█████▎    | 177/330 [35:07<30:21, 11.91s/it, loss=1.8, v_num=0] loss embedd 143.14273071289062\n",
      "loss 1.7044305801391602\n",
      "Epoch 0:  54%|█████▍    | 178/330 [35:19<30:09, 11.91s/it, loss=1.8, v_num=0]loss embedd 117.33283996582031\n",
      "loss 1.3069955110549927\n",
      "Epoch 0:  54%|█████▍    | 179/330 [35:31<29:57, 11.91s/it, loss=1.77, v_num=0]loss embedd 93.51242065429688\n",
      "loss 1.729066014289856\n",
      "Epoch 0:  55%|█████▍    | 180/330 [35:42<29:45, 11.91s/it, loss=1.76, v_num=0]loss embedd 68.08710479736328\n",
      "loss 1.5011959075927734\n",
      "Epoch 0:  55%|█████▍    | 181/330 [35:54<29:33, 11.91s/it, loss=1.76, v_num=0]loss embedd 71.20310974121094\n",
      "loss 1.6301778554916382\n",
      "Epoch 0:  55%|█████▌    | 182/330 [36:06<29:21, 11.91s/it, loss=1.74, v_num=0]loss embedd 84.64173889160156\n",
      "loss 1.640302062034607\n",
      "Epoch 0:  55%|█████▌    | 183/330 [36:18<29:10, 11.91s/it, loss=1.73, v_num=0]loss embedd 100.08207702636719\n",
      "loss 1.5224580764770508\n",
      "Epoch 0:  56%|█████▌    | 184/330 [36:30<28:58, 11.91s/it, loss=1.71, v_num=0]loss embedd 135.74960327148438\n",
      "loss 1.093615174293518\n",
      "Epoch 0:  56%|█████▌    | 185/330 [36:42<28:46, 11.90s/it, loss=1.68, v_num=0]loss embedd 212.84786987304688\n",
      "loss 1.659140944480896\n",
      "Epoch 0:  56%|█████▋    | 186/330 [36:54<28:34, 11.90s/it, loss=1.68, v_num=0]loss embedd 263.55426025390625\n",
      "loss 1.4951708316802979\n",
      "Epoch 0:  57%|█████▋    | 187/330 [37:06<28:22, 11.90s/it, loss=1.66, v_num=0]loss embedd 252.18443298339844\n",
      "loss 1.4751498699188232\n",
      "Epoch 0:  57%|█████▋    | 188/330 [37:18<28:10, 11.90s/it, loss=1.64, v_num=0]loss embedd 215.5767822265625\n",
      "loss 1.8545255661010742\n",
      "Epoch 0:  57%|█████▋    | 189/330 [37:30<27:58, 11.91s/it, loss=1.65, v_num=0]loss embedd 151.24217224121094\n",
      "loss 1.612916350364685\n",
      "Epoch 0:  58%|█████▊    | 190/330 [37:41<27:46, 11.90s/it, loss=1.63, v_num=0]loss embedd 98.21832275390625\n",
      "loss 0.9796348214149475\n",
      "Epoch 0:  58%|█████▊    | 191/330 [37:53<27:34, 11.90s/it, loss=1.6, v_num=0] loss embedd 91.46195983886719\n",
      "loss 1.58330237865448\n",
      "Epoch 0:  58%|█████▊    | 192/330 [38:05<27:22, 11.90s/it, loss=1.59, v_num=0]loss embedd 80.81890869140625\n",
      "loss 1.8213213682174683\n",
      "Epoch 0:  58%|█████▊    | 193/330 [38:17<27:10, 11.90s/it, loss=1.6, v_num=0] loss embedd 74.36253356933594\n",
      "loss 1.5265575647354126\n",
      "Epoch 0:  59%|█████▉    | 194/330 [38:29<26:58, 11.90s/it, loss=1.58, v_num=0]loss embedd 68.30216979980469\n",
      "loss 1.5820977687835693\n",
      "Epoch 0:  59%|█████▉    | 195/330 [38:41<26:47, 11.90s/it, loss=1.58, v_num=0]loss embedd 81.40815734863281\n",
      "loss 1.7757318019866943\n",
      "Epoch 0:  59%|█████▉    | 196/330 [38:53<26:35, 11.90s/it, loss=1.55, v_num=0]loss embedd 90.86973571777344\n",
      "loss 1.5507535934448242\n",
      "Epoch 0:  60%|█████▉    | 197/330 [39:05<26:23, 11.90s/it, loss=1.55, v_num=0]loss embedd 121.2105712890625\n",
      "loss 1.5338521003723145\n",
      "Epoch 0:  60%|██████    | 198/330 [39:16<26:11, 11.90s/it, loss=1.54, v_num=0]loss embedd 140.70321655273438\n",
      "loss 1.4110862016677856\n",
      "Epoch 0:  60%|██████    | 199/330 [39:28<25:59, 11.90s/it, loss=1.55, v_num=0]loss embedd 171.61996459960938\n",
      "loss 1.1860473155975342\n",
      "Epoch 0:  61%|██████    | 200/330 [39:40<25:47, 11.90s/it, loss=1.52, v_num=0]loss embedd 224.79718017578125\n",
      "loss 1.5590293407440186\n",
      "Epoch 0:  61%|██████    | 201/330 [39:52<25:35, 11.90s/it, loss=1.52, v_num=0]loss embedd 241.46697998046875\n",
      "loss 2.2278330326080322\n",
      "Epoch 0:  61%|██████    | 202/330 [40:04<25:23, 11.90s/it, loss=1.55, v_num=0]loss embedd 201.4395751953125\n",
      "loss 1.088953971862793\n",
      "Epoch 0:  62%|██████▏   | 203/330 [40:16<25:11, 11.90s/it, loss=1.53, v_num=0]loss embedd 170.39242553710938\n",
      "loss 1.5395174026489258\n",
      "Epoch 0:  62%|██████▏   | 204/330 [40:28<24:59, 11.90s/it, loss=1.53, v_num=0]loss embedd 126.94444274902344\n",
      "loss 1.5825536251068115\n",
      "Epoch 0:  62%|██████▏   | 205/330 [40:40<24:47, 11.90s/it, loss=1.55, v_num=0]loss embedd 82.64897918701172\n",
      "loss 1.6603808403015137\n",
      "Epoch 0:  62%|██████▏   | 206/330 [40:50<24:35, 11.90s/it, loss=1.55, v_num=0]loss embedd 63.152931213378906\n",
      "loss 1.7240965366363525\n",
      "Epoch 0:  63%|██████▎   | 207/330 [41:02<24:23, 11.90s/it, loss=1.56, v_num=0]loss embedd 51.206756591796875\n",
      "loss 1.4098402261734009\n",
      "Epoch 0:  63%|██████▎   | 208/330 [41:14<24:11, 11.90s/it, loss=1.56, v_num=0]loss embedd 50.03911590576172\n",
      "loss 1.8657758235931396\n",
      "Epoch 0:  63%|██████▎   | 209/330 [41:26<23:59, 11.90s/it, loss=1.56, v_num=0]loss embedd 49.6179313659668\n",
      "loss 1.4011932611465454\n",
      "Epoch 0:  64%|██████▎   | 210/330 [41:38<23:47, 11.90s/it, loss=1.55, v_num=0]loss embedd 65.2365951538086\n",
      "loss 1.5373132228851318\n",
      "Epoch 0:  64%|██████▍   | 211/330 [41:50<23:35, 11.90s/it, loss=1.58, v_num=0]loss embedd 88.72318267822266\n",
      "loss 1.3208221197128296\n",
      "Epoch 0:  64%|██████▍   | 212/330 [42:02<23:23, 11.90s/it, loss=1.57, v_num=0]loss embedd 111.34518432617188\n",
      "loss 1.5045057535171509\n",
      "Epoch 0:  65%|██████▍   | 213/330 [42:14<23:12, 11.90s/it, loss=1.55, v_num=0]loss embedd 133.87435913085938\n",
      "loss 1.4837908744812012\n",
      "Epoch 0:  65%|██████▍   | 214/330 [42:26<23:00, 11.90s/it, loss=1.55, v_num=0]loss embedd 134.7150421142578\n",
      "loss 1.520531177520752\n",
      "Epoch 0:  65%|██████▌   | 215/330 [42:37<22:48, 11.90s/it, loss=1.54, v_num=0]loss embedd 122.64732360839844\n",
      "loss 1.3948801755905151\n",
      "Epoch 0:  65%|██████▌   | 216/330 [42:49<22:36, 11.90s/it, loss=1.53, v_num=0]loss embedd 131.58616638183594\n",
      "loss 1.4684112071990967\n",
      "Epoch 0:  66%|██████▌   | 217/330 [43:01<22:24, 11.90s/it, loss=1.52, v_num=0]loss embedd 133.22769165039062\n",
      "loss 1.7483830451965332\n",
      "Epoch 0:  66%|██████▌   | 218/330 [43:13<22:12, 11.90s/it, loss=1.53, v_num=0]loss embedd 107.72051239013672\n",
      "loss 1.991659164428711\n",
      "Epoch 0:  66%|██████▋   | 219/330 [43:25<22:00, 11.90s/it, loss=1.56, v_num=0]loss embedd 76.78142547607422\n",
      "loss 1.320328950881958\n",
      "Epoch 0:  67%|██████▋   | 220/330 [43:37<21:48, 11.90s/it, loss=1.57, v_num=0]loss embedd 59.10243225097656\n",
      "loss 1.1840623617172241\n",
      "Epoch 0:  67%|██████▋   | 221/330 [43:49<21:36, 11.90s/it, loss=1.55, v_num=0]loss embedd 57.205474853515625\n",
      "loss 1.6018766164779663\n",
      "Epoch 0:  67%|██████▋   | 222/330 [44:01<21:24, 11.90s/it, loss=1.52, v_num=0]loss embedd 64.44818115234375\n",
      "loss 1.4407732486724854\n",
      "Epoch 0:  68%|██████▊   | 223/330 [44:13<21:12, 11.90s/it, loss=1.54, v_num=0]loss embedd 59.5733757019043\n",
      "loss 1.4571958780288696\n",
      "Epoch 0:  68%|██████▊   | 224/330 [44:24<21:01, 11.90s/it, loss=1.53, v_num=0]loss embedd 81.58308410644531\n",
      "loss 1.286610722541809\n",
      "Epoch 0:  68%|██████▊   | 225/330 [44:36<20:49, 11.90s/it, loss=1.52, v_num=0]loss embedd 91.32898712158203\n",
      "loss 1.6916378736495972\n",
      "Epoch 0:  68%|██████▊   | 226/330 [44:48<20:37, 11.90s/it, loss=1.52, v_num=0]loss embedd 116.05226135253906\n",
      "loss 1.3975986242294312\n",
      "Epoch 0:  69%|██████▉   | 227/330 [45:00<20:25, 11.90s/it, loss=1.5, v_num=0] loss embedd 124.02188110351562\n",
      "loss 1.3048017024993896\n",
      "Epoch 0:  69%|██████▉   | 228/330 [45:12<20:13, 11.90s/it, loss=1.5, v_num=0]loss embedd 134.49546813964844\n",
      "loss 2.3730521202087402\n",
      "Epoch 0:  69%|██████▉   | 229/330 [45:24<20:01, 11.90s/it, loss=1.52, v_num=0]loss embedd 127.04142761230469\n",
      "loss 1.871393084526062\n",
      "Epoch 0:  70%|██████▉   | 230/330 [45:36<19:49, 11.90s/it, loss=1.54, v_num=0]loss embedd 105.30851745605469\n",
      "loss 2.042231798171997\n",
      "Epoch 0:  70%|███████   | 231/330 [45:48<19:37, 11.90s/it, loss=1.57, v_num=0]loss embedd 79.20923614501953\n",
      "loss 1.5536011457443237\n",
      "Epoch 0:  70%|███████   | 232/330 [46:00<19:25, 11.90s/it, loss=1.58, v_num=0]loss embedd 68.21009063720703\n",
      "loss 1.5094579458236694\n",
      "Epoch 0:  71%|███████   | 233/330 [46:11<19:13, 11.90s/it, loss=1.58, v_num=0]loss embedd 53.825653076171875\n",
      "loss 1.7875542640686035\n",
      "Epoch 0:  71%|███████   | 234/330 [46:23<19:02, 11.90s/it, loss=1.6, v_num=0] loss embedd 49.202171325683594\n",
      "loss 1.6451051235198975\n",
      "Epoch 0:  71%|███████   | 235/330 [46:35<18:50, 11.90s/it, loss=1.6, v_num=0]loss embedd 57.097877502441406\n",
      "loss 1.519248127937317\n",
      "Epoch 0:  72%|███████▏  | 236/330 [46:47<18:38, 11.90s/it, loss=1.61, v_num=0]loss embedd 70.57100677490234\n",
      "loss 1.4792759418487549\n",
      "Epoch 0:  72%|███████▏  | 237/330 [46:59<18:26, 11.90s/it, loss=1.61, v_num=0]loss embedd 71.43281555175781\n",
      "loss 1.210690975189209\n",
      "Epoch 0:  72%|███████▏  | 238/330 [47:11<18:14, 11.90s/it, loss=1.58, v_num=0]loss embedd 100.69862365722656\n",
      "loss 1.8263764381408691\n",
      "Epoch 0:  72%|███████▏  | 239/330 [47:23<18:02, 11.90s/it, loss=1.58, v_num=0]loss embedd 118.49903869628906\n",
      "loss 1.3321599960327148\n",
      "Epoch 0:  73%|███████▎  | 240/330 [47:35<17:50, 11.90s/it, loss=1.58, v_num=0]loss embedd 113.00053405761719\n",
      "loss 1.149417757987976\n",
      "Epoch 0:  73%|███████▎  | 241/330 [47:47<17:38, 11.90s/it, loss=1.57, v_num=0]loss embedd 143.32821655273438\n",
      "loss 1.4151057004928589\n",
      "Epoch 0:  73%|███████▎  | 242/330 [47:58<17:26, 11.90s/it, loss=1.56, v_num=0]loss embedd 176.73500061035156\n",
      "loss 1.8339730501174927\n",
      "Epoch 0:  74%|███████▎  | 243/330 [48:10<17:15, 11.90s/it, loss=1.58, v_num=0]loss embedd 176.31686401367188\n",
      "loss 1.8480161428451538\n",
      "Epoch 0:  74%|███████▍  | 244/330 [48:22<17:03, 11.90s/it, loss=1.6, v_num=0] loss embedd 133.44764709472656\n",
      "loss 1.089969515800476\n",
      "Epoch 0:  74%|███████▍  | 245/330 [48:34<16:51, 11.90s/it, loss=1.59, v_num=0]loss embedd 119.99830627441406\n",
      "loss 1.170072078704834\n",
      "Epoch 0:  75%|███████▍  | 246/330 [48:46<16:39, 11.90s/it, loss=1.57, v_num=0]loss embedd 85.88282775878906\n",
      "loss 1.5655204057693481\n",
      "Epoch 0:  75%|███████▍  | 247/330 [48:58<16:27, 11.90s/it, loss=1.58, v_num=0]loss embedd 69.78987884521484\n",
      "loss 1.3344955444335938\n",
      "Epoch 0:  75%|███████▌  | 248/330 [49:10<16:15, 11.90s/it, loss=1.58, v_num=0]loss embedd 62.60001754760742\n",
      "loss 1.4612090587615967\n",
      "Epoch 0:  75%|███████▌  | 249/330 [49:22<16:03, 11.90s/it, loss=1.53, v_num=0]loss embedd 51.899085998535156\n",
      "loss 1.5695730447769165\n",
      "Epoch 0:  76%|███████▌  | 250/330 [49:34<15:51, 11.90s/it, loss=1.52, v_num=0]loss embedd 57.90778350830078\n",
      "loss 1.5029497146606445\n",
      "Epoch 0:  76%|███████▌  | 251/330 [49:45<15:39, 11.90s/it, loss=1.49, v_num=0]loss embedd 58.39939880371094\n",
      "loss 1.4289565086364746\n",
      "Epoch 0:  76%|███████▋  | 252/330 [49:57<15:27, 11.90s/it, loss=1.48, v_num=0]loss embedd 86.50542449951172\n",
      "loss 1.7344448566436768\n",
      "Epoch 0:  77%|███████▋  | 253/330 [50:09<15:15, 11.90s/it, loss=1.5, v_num=0] loss embedd 100.31307983398438\n",
      "loss 1.4870294332504272\n",
      "Epoch 0:  77%|███████▋  | 254/330 [50:21<15:04, 11.90s/it, loss=1.48, v_num=0]loss embedd 118.66085815429688\n",
      "loss 1.8310799598693848\n",
      "Epoch 0:  77%|███████▋  | 255/330 [50:33<14:52, 11.90s/it, loss=1.49, v_num=0]loss embedd 110.98143768310547\n",
      "loss 1.3365650177001953\n",
      "Epoch 0:  78%|███████▊  | 256/330 [50:45<14:40, 11.90s/it, loss=1.48, v_num=0]loss embedd 113.36799621582031\n",
      "loss 1.352386713027954\n",
      "Epoch 0:  78%|███████▊  | 257/330 [50:57<14:28, 11.90s/it, loss=1.47, v_num=0]loss embedd 102.54679870605469\n",
      "loss 1.2482225894927979\n",
      "Epoch 0:  78%|███████▊  | 258/330 [51:09<14:16, 11.90s/it, loss=1.48, v_num=0]loss embedd 105.90988159179688\n",
      "loss 1.54831862449646\n",
      "Epoch 0:  78%|███████▊  | 259/330 [51:21<14:04, 11.90s/it, loss=1.46, v_num=0]loss embedd 101.1587905883789\n",
      "loss 1.4468133449554443\n",
      "Epoch 0:  79%|███████▉  | 260/330 [51:32<13:52, 11.90s/it, loss=1.47, v_num=0]loss embedd 96.91582489013672\n",
      "loss 1.1738930940628052\n",
      "Epoch 0:  79%|███████▉  | 261/330 [51:44<13:40, 11.90s/it, loss=1.47, v_num=0]loss embedd 97.107421875\n",
      "loss 1.3038673400878906\n",
      "Epoch 0:  79%|███████▉  | 262/330 [51:56<13:28, 11.90s/it, loss=1.46, v_num=0]loss embedd 102.84165954589844\n",
      "loss 1.0939788818359375\n",
      "Epoch 0:  80%|███████▉  | 263/330 [52:08<13:17, 11.90s/it, loss=1.43, v_num=0]loss embedd 95.19510650634766\n",
      "loss 1.583876609802246\n",
      "Epoch 0:  80%|████████  | 264/330 [52:20<13:05, 11.90s/it, loss=1.41, v_num=0]loss embedd 103.40446472167969\n",
      "loss 1.514715313911438\n",
      "Epoch 0:  80%|████████  | 265/330 [52:32<12:53, 11.90s/it, loss=1.43, v_num=0]loss embedd 108.68122100830078\n",
      "loss 1.3530436754226685\n",
      "Epoch 0:  81%|████████  | 266/330 [52:44<12:41, 11.90s/it, loss=1.44, v_num=0]loss embedd 107.73283386230469\n",
      "loss 1.2681169509887695\n",
      "Epoch 0:  81%|████████  | 267/330 [52:56<12:29, 11.90s/it, loss=1.43, v_num=0]loss embedd 96.37553405761719\n",
      "loss 1.5289844274520874\n",
      "Epoch 0:  81%|████████  | 268/330 [53:08<12:17, 11.90s/it, loss=1.44, v_num=0]loss embedd 89.66433715820312\n",
      "loss 0.9460435509681702\n",
      "Epoch 0:  82%|████████▏ | 269/330 [53:20<12:05, 11.90s/it, loss=1.41, v_num=0]loss embedd 78.20405578613281\n",
      "loss 1.5797468423843384\n",
      "Epoch 0:  82%|████████▏ | 270/330 [53:31<11:53, 11.90s/it, loss=1.41, v_num=0]loss embedd 75.507568359375\n",
      "loss 1.3541525602340698\n",
      "Epoch 0:  82%|████████▏ | 271/330 [53:43<11:41, 11.90s/it, loss=1.41, v_num=0]loss embedd 89.93253326416016\n",
      "loss 1.443077564239502\n",
      "Epoch 0:  82%|████████▏ | 272/330 [53:55<11:29, 11.90s/it, loss=1.41, v_num=0]loss embedd 97.31233215332031\n",
      "loss 0.9949235320091248\n",
      "Epoch 0:  83%|████████▎ | 273/330 [54:07<11:18, 11.90s/it, loss=1.37, v_num=0]loss embedd 140.25424194335938\n",
      "loss 1.184173822402954\n",
      "Epoch 0:  83%|████████▎ | 274/330 [54:19<11:06, 11.90s/it, loss=1.35, v_num=0]loss embedd 187.27053833007812\n",
      "loss 1.856374740600586\n",
      "Epoch 0:  83%|████████▎ | 275/330 [54:31<10:54, 11.90s/it, loss=1.36, v_num=0]loss embedd 188.61399841308594\n",
      "loss 1.5674604177474976\n",
      "Epoch 0:  84%|████████▎ | 276/330 [54:43<10:42, 11.90s/it, loss=1.37, v_num=0]loss embedd 159.87225341796875\n",
      "loss 1.2766187191009521\n",
      "Epoch 0:  84%|████████▍ | 277/330 [54:55<10:30, 11.90s/it, loss=1.36, v_num=0]loss embedd 110.43518829345703\n",
      "loss 1.6496158838272095\n",
      "Epoch 0:  84%|████████▍ | 278/330 [55:07<10:18, 11.90s/it, loss=1.38, v_num=0]loss embedd 62.265724182128906\n",
      "loss 1.540175199508667\n",
      "Epoch 0:  85%|████████▍ | 279/330 [55:19<10:06, 11.90s/it, loss=1.38, v_num=0]loss embedd 65.91168975830078\n",
      "loss 1.329967975616455\n",
      "Epoch 0:  85%|████████▍ | 280/330 [55:30<09:54, 11.90s/it, loss=1.38, v_num=0]loss embedd 82.84857177734375\n",
      "loss 1.432469367980957\n",
      "Epoch 0:  85%|████████▌ | 281/330 [55:42<09:42, 11.90s/it, loss=1.39, v_num=0]loss embedd 122.21598815917969\n",
      "loss 1.237694501876831\n",
      "Epoch 0:  85%|████████▌ | 282/330 [55:54<09:31, 11.90s/it, loss=1.39, v_num=0]loss embedd 129.08248901367188\n",
      "loss 1.3697364330291748\n",
      "Epoch 0:  86%|████████▌ | 283/330 [56:06<09:19, 11.90s/it, loss=1.4, v_num=0] loss embedd 135.81739807128906\n",
      "loss 1.0738104581832886\n",
      "Epoch 0:  86%|████████▌ | 284/330 [56:18<09:07, 11.90s/it, loss=1.38, v_num=0]loss embedd 137.68453979492188\n",
      "loss 1.4028229713439941\n",
      "Epoch 0:  86%|████████▋ | 285/330 [56:30<08:55, 11.90s/it, loss=1.37, v_num=0]loss embedd 131.79586791992188\n",
      "loss 1.3974906206130981\n",
      "Epoch 0:  87%|████████▋ | 286/330 [56:42<08:43, 11.90s/it, loss=1.37, v_num=0]loss embedd 103.9346694946289\n",
      "loss 1.2074270248413086\n",
      "Epoch 0:  87%|████████▋ | 287/330 [56:54<08:31, 11.90s/it, loss=1.37, v_num=0]loss embedd 77.71199035644531\n",
      "loss 1.0415780544281006\n",
      "Epoch 0:  87%|████████▋ | 288/330 [57:06<08:19, 11.90s/it, loss=1.34, v_num=0]loss embedd 114.96622467041016\n",
      "loss 1.0835860967636108\n",
      "Epoch 0:  88%|████████▊ | 289/330 [57:18<08:07, 11.90s/it, loss=1.35, v_num=0]loss embedd 107.10919189453125\n",
      "loss 1.1950292587280273\n",
      "Epoch 0:  88%|████████▊ | 290/330 [57:30<07:55, 11.90s/it, loss=1.33, v_num=0]loss embedd 89.40667724609375\n",
      "loss 1.0601844787597656\n",
      "Epoch 0:  88%|████████▊ | 291/330 [57:42<07:44, 11.90s/it, loss=1.32, v_num=0]loss embedd 86.7475357055664\n",
      "loss 1.1246742010116577\n",
      "Epoch 0:  88%|████████▊ | 292/330 [57:54<07:32, 11.90s/it, loss=1.3, v_num=0] loss embedd 143.26486206054688\n",
      "loss 1.4945868253707886\n",
      "Epoch 0:  89%|████████▉ | 293/330 [58:06<07:20, 11.90s/it, loss=1.33, v_num=0]loss embedd 81.28089141845703\n",
      "loss 1.3047313690185547\n",
      "Epoch 0:  89%|████████▉ | 294/330 [58:18<07:08, 11.90s/it, loss=1.33, v_num=0]loss embedd 73.49928283691406\n",
      "loss 1.5045429468154907\n",
      "Epoch 0:  89%|████████▉ | 295/330 [58:30<06:56, 11.90s/it, loss=1.31, v_num=0]loss embedd 164.8824920654297\n",
      "loss 1.4136769771575928\n",
      "Epoch 0:  90%|████████▉ | 296/330 [58:42<06:44, 11.90s/it, loss=1.31, v_num=0]loss embedd 260.17315673828125\n",
      "loss 1.5943065881729126\n",
      "Epoch 0:  90%|█████████ | 297/330 [58:53<06:32, 11.90s/it, loss=1.32, v_num=0]loss embedd 245.57150268554688\n",
      "loss 1.4709073305130005\n",
      "Epoch 0:  90%|█████████ | 298/330 [59:05<06:20, 11.90s/it, loss=1.31, v_num=0]loss embedd 135.9531707763672\n",
      "loss 1.0769509077072144\n",
      "Epoch 0:  91%|█████████ | 299/330 [59:17<06:08, 11.90s/it, loss=1.29, v_num=0]loss embedd 96.18620300292969\n",
      "loss 1.8052875995635986\n",
      "Epoch 0:  91%|█████████ | 300/330 [59:29<05:56, 11.90s/it, loss=1.31, v_num=0]loss embedd 133.36732482910156\n",
      "loss 1.4536412954330444\n",
      "Epoch 0:  91%|█████████ | 301/330 [59:41<05:45, 11.90s/it, loss=1.32, v_num=0]loss embedd 101.97575378417969\n",
      "loss 1.0592501163482666\n",
      "Epoch 0:  92%|█████████▏| 302/330 [59:53<05:33, 11.90s/it, loss=1.31, v_num=0]loss embedd 102.40789031982422\n",
      "loss 1.376278281211853\n",
      "Epoch 0:  92%|█████████▏| 303/330 [1:00:05<05:21, 11.90s/it, loss=1.31, v_num=0]loss embedd 83.156005859375\n",
      "loss 1.027400016784668\n",
      "Epoch 0:  92%|█████████▏| 304/330 [1:00:17<05:09, 11.90s/it, loss=1.3, v_num=0] loss embedd 90.78633117675781\n",
      "loss 0.9981192946434021\n",
      "Epoch 0:  92%|█████████▏| 305/330 [1:00:29<04:57, 11.90s/it, loss=1.28, v_num=0]loss embedd 116.6854019165039\n",
      "loss 1.2537715435028076\n",
      "Epoch 0:  93%|█████████▎| 306/330 [1:00:41<04:45, 11.90s/it, loss=1.28, v_num=0]loss embedd 131.5831298828125\n",
      "loss 1.1294772624969482\n",
      "Epoch 0:  93%|█████████▎| 307/330 [1:00:53<04:33, 11.90s/it, loss=1.27, v_num=0]loss embedd 181.78109741210938\n",
      "loss 1.7846577167510986\n",
      "Epoch 0:  93%|█████████▎| 308/330 [1:01:05<04:21, 11.90s/it, loss=1.31, v_num=0]loss embedd 172.59133911132812\n",
      "loss 1.044508457183838\n",
      "Epoch 0:  94%|█████████▎| 309/330 [1:01:16<04:09, 11.90s/it, loss=1.31, v_num=0]loss embedd 161.96910095214844\n",
      "loss 1.4412693977355957\n",
      "Epoch 0:  94%|█████████▍| 310/330 [1:01:28<03:57, 11.90s/it, loss=1.32, v_num=0]loss embedd 132.17947387695312\n",
      "loss 1.6582467555999756\n",
      "Epoch 0:  94%|█████████▍| 311/330 [1:01:40<03:46, 11.90s/it, loss=1.35, v_num=0]loss embedd 96.93229675292969\n",
      "loss 1.1912736892700195\n",
      "Epoch 0:  95%|█████████▍| 312/330 [1:01:52<03:34, 11.90s/it, loss=1.35, v_num=0]loss embedd 80.50638580322266\n",
      "loss 1.3799089193344116\n",
      "Epoch 0:  95%|█████████▍| 313/330 [1:02:04<03:22, 11.90s/it, loss=1.35, v_num=0]loss embedd 62.872154235839844\n",
      "loss 1.204013705253601\n",
      "Epoch 0:  95%|█████████▌| 314/330 [1:02:16<03:10, 11.90s/it, loss=1.34, v_num=0]loss embedd 55.22039794921875\n",
      "loss 1.3341116905212402\n",
      "Epoch 0:  95%|█████████▌| 315/330 [1:02:27<02:58, 11.90s/it, loss=1.33, v_num=0]loss embedd 61.86439514160156\n",
      "loss 1.0620765686035156\n",
      "Epoch 0:  96%|█████████▌| 316/330 [1:02:39<02:46, 11.90s/it, loss=1.32, v_num=0]loss embedd 79.65599060058594\n",
      "loss 1.2163032293319702\n",
      "Epoch 0:  96%|█████████▌| 317/330 [1:02:51<02:34, 11.90s/it, loss=1.3, v_num=0] loss embedd 131.92495727539062\n",
      "loss 1.4153934717178345\n",
      "Epoch 0:  96%|█████████▋| 318/330 [1:03:02<02:22, 11.90s/it, loss=1.3, v_num=0]loss embedd 140.0352325439453\n",
      "loss 1.6117099523544312\n",
      "Epoch 0:  97%|█████████▋| 319/330 [1:03:14<02:10, 11.90s/it, loss=1.32, v_num=0]loss embedd 137.60287475585938\n",
      "loss 0.9025682806968689\n",
      "Epoch 0:  97%|█████████▋| 320/330 [1:03:26<01:58, 11.90s/it, loss=1.28, v_num=0]loss embedd 102.96876525878906\n",
      "loss 1.3533498048782349\n",
      "Epoch 0:  97%|█████████▋| 321/330 [1:03:38<01:47, 11.90s/it, loss=1.27, v_num=0]loss embedd 98.60202026367188\n",
      "loss 1.287276029586792\n",
      "Epoch 0:  98%|█████████▊| 322/330 [1:03:50<01:35, 11.90s/it, loss=1.28, v_num=0]loss embedd 58.90667724609375\n",
      "loss 1.0178956985473633\n",
      "Epoch 0:  98%|█████████▊| 323/330 [1:04:02<01:23, 11.90s/it, loss=1.27, v_num=0]loss embedd 68.2933120727539\n",
      "loss 1.2272270917892456\n",
      "Epoch 0:  98%|█████████▊| 324/330 [1:04:14<01:11, 11.90s/it, loss=1.28, v_num=0]loss embedd 74.54698944091797\n",
      "loss 1.2722325325012207\n",
      "Epoch 0:  98%|█████████▊| 325/330 [1:04:26<00:59, 11.90s/it, loss=1.29, v_num=0]loss embedd 103.03207397460938\n",
      "loss 1.0060474872589111\n",
      "Epoch 0:  99%|█████████▉| 326/330 [1:04:37<00:47, 11.90s/it, loss=1.28, v_num=0]loss embedd 113.45158386230469\n",
      "loss 1.2699276208877563\n",
      "Epoch 0:  99%|█████████▉| 327/330 [1:04:49<00:35, 11.90s/it, loss=1.28, v_num=0]loss embedd 110.1854248046875\n",
      "loss 1.0868858098983765\n",
      "Epoch 0:  99%|█████████▉| 328/330 [1:05:01<00:23, 11.90s/it, loss=1.25, v_num=0]loss embedd 99.99952697753906\n",
      "loss 0.910817563533783\n",
      "Epoch 0: 100%|█████████▉| 329/330 [1:05:13<00:11, 11.90s/it, loss=1.24, v_num=0]loss embedd 111.27578735351562\n",
      "loss 1.1939407587051392\n",
      "Epoch 1:   0%|          | 0/330 [00:00<?, ?it/s, loss=1.23, v_num=0]            loss embedd 92.47244262695312\n",
      "loss 1.6054364442825317\n",
      "Epoch 1:   0%|          | 1/330 [00:15<1:22:18, 15.01s/it, loss=1.23, v_num=0]loss embedd 67.36776733398438\n",
      "loss 1.4211194515228271\n",
      "Epoch 1:   1%|          | 2/330 [00:26<1:13:35, 13.46s/it, loss=1.24, v_num=0]loss embedd 57.29731750488281\n",
      "loss 1.2441269159317017\n",
      "Epoch 1:   1%|          | 3/330 [00:38<1:10:42, 12.97s/it, loss=1.23, v_num=0]loss embedd 58.55973815917969\n",
      "loss 1.3794238567352295\n",
      "Epoch 1:   1%|          | 4/330 [00:50<1:09:06, 12.72s/it, loss=1.24, v_num=0]loss embedd 77.43938446044922\n",
      "loss 1.4306130409240723\n",
      "Epoch 1:   2%|▏         | 5/330 [01:02<1:08:02, 12.56s/it, loss=1.25, v_num=0]loss embedd 101.64628601074219\n",
      "loss 1.3299634456634521\n",
      "Epoch 1:   2%|▏         | 6/330 [01:14<1:07:13, 12.45s/it, loss=1.26, v_num=0]loss embedd 134.28274536132812\n",
      "loss 1.0023363828659058\n",
      "Epoch 1:   2%|▏         | 7/330 [01:26<1:06:36, 12.37s/it, loss=1.25, v_num=0]loss embedd 182.53314208984375\n",
      "loss 1.8500186204910278\n",
      "Epoch 1:   2%|▏         | 8/330 [01:38<1:06:05, 12.31s/it, loss=1.27, v_num=0]loss embedd 174.114990234375\n",
      "loss 1.766859769821167\n",
      "Epoch 1:   3%|▎         | 9/330 [01:50<1:05:39, 12.27s/it, loss=1.28, v_num=0]loss embedd 116.49849700927734\n",
      "loss 1.5481064319610596\n",
      "Epoch 1:   3%|▎         | 10/330 [02:02<1:05:14, 12.23s/it, loss=1.31, v_num=0]loss embedd 85.13203430175781\n",
      "loss 1.0236471891403198\n",
      "Epoch 1:   3%|▎         | 11/330 [02:14<1:04:52, 12.20s/it, loss=1.29, v_num=0]loss embedd 53.626502990722656\n",
      "loss 1.1450080871582031\n",
      "Epoch 1:   4%|▎         | 12/330 [02:26<1:04:33, 12.18s/it, loss=1.29, v_num=0]loss embedd 54.0552978515625\n",
      "loss 1.600608468055725\n",
      "Epoch 1:   4%|▍         | 13/330 [02:38<1:04:18, 12.17s/it, loss=1.32, v_num=0]loss embedd 54.94163513183594\n",
      "loss 1.6432663202285767\n",
      "Epoch 1:   4%|▍         | 14/330 [02:50<1:04:00, 12.15s/it, loss=1.34, v_num=0]loss embedd 58.86727523803711\n",
      "loss 1.137015700340271\n",
      "Epoch 1:   5%|▍         | 15/330 [03:02<1:03:44, 12.14s/it, loss=1.33, v_num=0]loss embedd 117.73345184326172\n",
      "loss 1.4205149412155151\n",
      "Epoch 1:   5%|▍         | 16/330 [03:14<1:03:27, 12.13s/it, loss=1.35, v_num=0]loss embedd 117.52340698242188\n",
      "loss 1.5128896236419678\n",
      "Epoch 1:   5%|▌         | 17/330 [03:25<1:03:12, 12.12s/it, loss=1.36, v_num=0]loss embedd 145.3893280029297\n",
      "loss 1.1947067975997925\n",
      "Epoch 1:   5%|▌         | 18/330 [03:37<1:02:57, 12.11s/it, loss=1.37, v_num=0]loss embedd 150.1397705078125\n",
      "loss 1.0039806365966797\n",
      "Epoch 1:   6%|▌         | 19/330 [03:49<1:02:41, 12.10s/it, loss=1.37, v_num=0]loss embedd 127.9515609741211\n",
      "loss 1.2677555084228516\n",
      "Epoch 1:   6%|▌         | 20/330 [04:01<1:02:26, 12.08s/it, loss=1.38, v_num=0]loss embedd 121.36241912841797\n",
      "loss 1.1931142807006836\n",
      "Epoch 1:   6%|▋         | 21/330 [04:13<1:02:11, 12.08s/it, loss=1.36, v_num=0]loss embedd 95.61701202392578\n",
      "loss 0.6250615119934082\n",
      "Epoch 1:   7%|▋         | 22/330 [04:25<1:01:57, 12.07s/it, loss=1.32, v_num=0]loss embedd 120.8400650024414\n",
      "loss 0.9891316294670105\n",
      "Epoch 1:   7%|▋         | 23/330 [04:37<1:01:42, 12.06s/it, loss=1.3, v_num=0] loss embedd 132.77500915527344\n",
      "loss 1.136725902557373\n",
      "Epoch 1:   7%|▋         | 24/330 [04:49<1:01:28, 12.06s/it, loss=1.29, v_num=0]loss embedd 130.03269958496094\n",
      "loss 1.5625559091567993\n",
      "Epoch 1:   8%|▊         | 25/330 [05:01<1:01:14, 12.05s/it, loss=1.3, v_num=0] loss embedd 108.6412353515625\n",
      "loss 1.0873281955718994\n",
      "Epoch 1:   8%|▊         | 26/330 [05:13<1:01:00, 12.04s/it, loss=1.29, v_num=0]loss embedd 88.8001708984375\n",
      "loss 0.9973659515380859\n",
      "Epoch 1:   8%|▊         | 27/330 [05:24<1:00:46, 12.04s/it, loss=1.29, v_num=0]loss embedd 66.3950424194336\n",
      "loss 0.9804450273513794\n",
      "Epoch 1:   8%|▊         | 28/330 [05:36<1:00:33, 12.03s/it, loss=1.24, v_num=0]loss embedd 74.62222290039062\n",
      "loss 1.0492823123931885\n",
      "Epoch 1:   9%|▉         | 29/330 [05:48<1:00:19, 12.03s/it, loss=1.21, v_num=0]loss embedd 83.87969970703125\n",
      "loss 1.4018826484680176\n",
      "Epoch 1:   9%|▉         | 30/330 [06:00<1:00:06, 12.02s/it, loss=1.2, v_num=0] loss embedd 91.27999877929688\n",
      "loss 0.8375161290168762\n",
      "Epoch 1:   9%|▉         | 31/330 [06:12<59:54, 12.02s/it, loss=1.19, v_num=0] loss embedd 98.65679931640625\n",
      "loss 1.3244951963424683\n",
      "Epoch 1:  10%|▉         | 32/330 [06:24<59:40, 12.02s/it, loss=1.2, v_num=0] loss embedd 84.0868148803711\n",
      "loss 1.2858198881149292\n",
      "Epoch 1:  10%|█         | 33/330 [06:36<59:27, 12.01s/it, loss=1.18, v_num=0]loss embedd 60.57048034667969\n",
      "loss 1.0593034029006958\n",
      "Epoch 1:  10%|█         | 34/330 [06:48<59:14, 12.01s/it, loss=1.15, v_num=0]loss embedd 50.32905578613281\n",
      "loss 1.4892083406448364\n",
      "Epoch 1:  11%|█         | 35/330 [07:00<59:03, 12.01s/it, loss=1.17, v_num=0]loss embedd 62.28562545776367\n",
      "loss 1.0425739288330078\n",
      "Epoch 1:  11%|█         | 36/330 [07:12<58:49, 12.01s/it, loss=1.15, v_num=0]loss embedd 106.51421356201172\n",
      "loss 1.5598359107971191\n",
      "Epoch 1:  11%|█         | 37/330 [07:24<58:36, 12.00s/it, loss=1.15, v_num=0]loss embedd 122.14712524414062\n",
      "loss 1.4014338254928589\n",
      "Epoch 1:  12%|█▏        | 38/330 [07:35<58:23, 12.00s/it, loss=1.16, v_num=0]loss embedd 148.57205200195312\n",
      "loss 1.1421209573745728\n",
      "Epoch 1:  12%|█▏        | 39/330 [07:47<58:10, 12.00s/it, loss=1.17, v_num=0]loss embedd 157.66522216796875\n",
      "loss 1.810060977935791\n",
      "Epoch 1:  12%|█▏        | 40/330 [07:59<57:58, 11.99s/it, loss=1.2, v_num=0] loss embedd 95.80628204345703\n",
      "loss 1.587808609008789\n",
      "Epoch 1:  12%|█▏        | 41/330 [08:11<57:45, 11.99s/it, loss=1.22, v_num=0]loss embedd 36.659339904785156\n",
      "loss 1.529339075088501\n",
      "Epoch 1:  13%|█▎        | 42/330 [08:23<57:32, 11.99s/it, loss=1.26, v_num=0]loss embedd 26.95891571044922\n",
      "loss 1.584633231163025\n",
      "Epoch 1:  13%|█▎        | 43/330 [08:35<57:20, 11.99s/it, loss=1.29, v_num=0]loss embedd 33.73324203491211\n",
      "loss 1.6295559406280518\n",
      "Epoch 1:  13%|█▎        | 44/330 [08:47<57:07, 11.99s/it, loss=1.32, v_num=0]loss embedd 62.861114501953125\n",
      "loss 1.0222300291061401\n",
      "Epoch 1:  14%|█▎        | 45/330 [08:59<56:55, 11.98s/it, loss=1.29, v_num=0]loss embedd 103.1817855834961\n",
      "loss 1.2256979942321777\n",
      "Epoch 1:  14%|█▍        | 46/330 [09:11<56:42, 11.98s/it, loss=1.3, v_num=0] loss embedd 187.36654663085938\n",
      "loss 1.5102570056915283\n",
      "Epoch 1:  14%|█▍        | 47/330 [09:22<56:29, 11.98s/it, loss=1.32, v_num=0]loss embedd 146.82749938964844\n",
      "loss 1.4793219566345215\n",
      "Epoch 1:  15%|█▍        | 48/330 [09:34<56:17, 11.98s/it, loss=1.35, v_num=0]loss embedd 134.15380859375\n",
      "loss 1.3789335489273071\n",
      "Epoch 1:  15%|█▍        | 49/330 [09:46<56:05, 11.98s/it, loss=1.37, v_num=0]loss embedd 76.19686889648438\n",
      "loss 1.545296549797058\n",
      "Epoch 1:  15%|█▌        | 50/330 [09:58<55:53, 11.98s/it, loss=1.37, v_num=0]loss embedd 49.261077880859375\n",
      "loss 0.9104949235916138\n",
      "Epoch 1:  15%|█▌        | 51/330 [10:10<55:41, 11.98s/it, loss=1.38, v_num=0]loss embedd 55.84680938720703\n",
      "loss 1.387649655342102\n",
      "Epoch 1:  16%|█▌        | 52/330 [10:22<55:28, 11.97s/it, loss=1.38, v_num=0]loss embedd 66.76200866699219\n",
      "loss 1.6700752973556519\n",
      "Epoch 1:  16%|█▌        | 53/330 [10:34<55:16, 11.97s/it, loss=1.4, v_num=0] loss embedd 88.34034729003906\n",
      "loss 1.040826678276062\n",
      "Epoch 1:  16%|█▋        | 54/330 [10:46<55:04, 11.97s/it, loss=1.4, v_num=0]loss embedd 126.29061889648438\n",
      "loss 0.5526870489120483\n",
      "Epoch 1:  17%|█▋        | 55/330 [10:58<54:52, 11.97s/it, loss=1.35, v_num=0]loss embedd 148.85780334472656\n",
      "loss 1.8288112878799438\n",
      "Epoch 1:  17%|█▋        | 56/330 [11:10<54:39, 11.97s/it, loss=1.39, v_num=0]loss embedd 153.9332275390625\n",
      "loss 1.7646293640136719\n",
      "Epoch 1:  17%|█▋        | 57/330 [11:22<54:27, 11.97s/it, loss=1.4, v_num=0] loss embedd 127.2070083618164\n",
      "loss 1.7803038358688354\n",
      "Epoch 1:  18%|█▊        | 58/330 [11:34<54:15, 11.97s/it, loss=1.42, v_num=0]loss embedd 52.48929977416992\n",
      "loss 1.721169352531433\n",
      "Epoch 1:  18%|█▊        | 59/330 [11:46<54:03, 11.97s/it, loss=1.45, v_num=0]loss embedd 17.894033432006836\n",
      "loss 1.6402082443237305\n",
      "Epoch 1:  18%|█▊        | 60/330 [11:57<53:50, 11.97s/it, loss=1.44, v_num=0]loss embedd 11.307530403137207\n",
      "loss 1.7919409275054932\n",
      "Epoch 1:  18%|█▊        | 61/330 [12:09<53:38, 11.96s/it, loss=1.45, v_num=0]loss embedd 6.583697319030762\n",
      "loss 1.9602773189544678\n",
      "Epoch 1:  19%|█▉        | 62/330 [12:21<53:26, 11.96s/it, loss=1.47, v_num=0]loss embedd 6.005128383636475\n",
      "loss 1.9066071510314941\n",
      "Epoch 1:  19%|█▉        | 63/330 [12:33<53:14, 11.96s/it, loss=1.49, v_num=0]loss embedd 6.546179294586182\n",
      "loss 1.9407621622085571\n",
      "Epoch 1:  19%|█▉        | 64/330 [12:45<53:02, 11.96s/it, loss=1.5, v_num=0] loss embedd 6.440155506134033\n",
      "loss 1.9331589937210083\n",
      "Epoch 1:  20%|█▉        | 65/330 [12:57<52:50, 11.96s/it, loss=1.55, v_num=0]loss embedd 8.839431762695312\n",
      "loss 2.0033867359161377\n",
      "Epoch 1:  20%|██        | 66/330 [13:09<52:38, 11.96s/it, loss=1.59, v_num=0]loss embedd 12.053861618041992\n",
      "loss 1.8220463991165161\n",
      "Epoch 1:  20%|██        | 67/330 [13:21<52:25, 11.96s/it, loss=1.6, v_num=0] loss embedd 25.02469825744629\n",
      "loss 1.5559371709823608\n",
      "Epoch 1:  21%|██        | 68/330 [13:33<52:13, 11.96s/it, loss=1.61, v_num=0]loss embedd 70.47848510742188\n",
      "loss 1.670186161994934\n",
      "Epoch 1:  21%|██        | 69/330 [13:45<52:01, 11.96s/it, loss=1.62, v_num=0]loss embedd 162.54595947265625\n",
      "loss 1.2397807836532593\n",
      "Epoch 1:  21%|██        | 70/330 [13:57<51:49, 11.96s/it, loss=1.61, v_num=0]loss embedd 218.78585815429688\n",
      "loss 2.5359232425689697\n",
      "Epoch 1:  22%|██▏       | 71/330 [14:08<51:37, 11.96s/it, loss=1.69, v_num=0]loss embedd 135.3740234375\n",
      "loss 1.7455037832260132\n",
      "Epoch 1:  22%|██▏       | 72/330 [14:20<51:24, 11.96s/it, loss=1.71, v_num=0]loss embedd 90.64646911621094\n",
      "loss 1.5791358947753906\n",
      "Epoch 1:  22%|██▏       | 73/330 [14:32<51:12, 11.96s/it, loss=1.7, v_num=0] loss embedd 63.514312744140625\n",
      "loss 1.7414923906326294\n",
      "Epoch 1:  22%|██▏       | 74/330 [14:44<51:00, 11.95s/it, loss=1.74, v_num=0]loss embedd 54.371315002441406\n",
      "loss 1.44977605342865\n",
      "Epoch 1:  23%|██▎       | 75/330 [14:56<50:48, 11.95s/it, loss=1.78, v_num=0]loss embedd 61.863155364990234\n",
      "loss 1.469590663909912\n",
      "Epoch 1:  23%|██▎       | 76/330 [15:08<50:36, 11.95s/it, loss=1.76, v_num=0]loss embedd 67.56877136230469\n",
      "loss 1.4758400917053223\n",
      "Epoch 1:  23%|██▎       | 77/330 [15:20<50:24, 11.95s/it, loss=1.75, v_num=0]loss embedd 73.131103515625\n",
      "loss 1.600858211517334\n",
      "Epoch 1:  24%|██▎       | 78/330 [15:32<50:12, 11.95s/it, loss=1.74, v_num=0]loss embedd 102.91636657714844\n",
      "loss 1.6754554510116577\n",
      "Epoch 1:  24%|██▍       | 79/330 [15:44<50:00, 11.95s/it, loss=1.74, v_num=0]loss embedd 96.70440673828125\n",
      "loss 1.3863325119018555\n",
      "Epoch 1:  24%|██▍       | 80/330 [15:56<49:48, 11.95s/it, loss=1.72, v_num=0]loss embedd 104.42200469970703\n",
      "loss 1.1991431713104248\n",
      "Epoch 1:  25%|██▍       | 81/330 [16:08<49:36, 11.95s/it, loss=1.69, v_num=0]loss embedd 128.33447265625\n",
      "loss 1.557829737663269\n",
      "Epoch 1:  25%|██▍       | 82/330 [16:20<49:23, 11.95s/it, loss=1.67, v_num=0]loss embedd 119.16064453125\n",
      "loss 0.9376237392425537\n",
      "Epoch 1:  25%|██▌       | 83/330 [16:31<49:11, 11.95s/it, loss=1.63, v_num=0]loss embedd 107.46571350097656\n",
      "loss 1.494789481163025\n",
      "Epoch 1:  25%|██▌       | 84/330 [16:43<48:59, 11.95s/it, loss=1.6, v_num=0] loss embedd 81.6500015258789\n",
      "loss 1.445494532585144\n",
      "Epoch 1:  26%|██▌       | 85/330 [16:55<48:47, 11.95s/it, loss=1.58, v_num=0]loss embedd 73.79253387451172\n",
      "loss 1.0505685806274414\n",
      "Epoch 1:  26%|██▌       | 86/330 [17:07<48:35, 11.95s/it, loss=1.53, v_num=0]loss embedd 54.739471435546875\n",
      "loss 1.3742485046386719\n",
      "Epoch 1:  26%|██▋       | 87/330 [17:19<48:23, 11.95s/it, loss=1.51, v_num=0]loss embedd 32.28665542602539\n",
      "loss 1.3446649312973022\n",
      "Epoch 1:  27%|██▋       | 88/330 [17:31<48:11, 11.95s/it, loss=1.5, v_num=0] loss embedd 38.5304069519043\n",
      "loss 1.708069086074829\n",
      "Epoch 1:  27%|██▋       | 89/330 [17:43<47:59, 11.95s/it, loss=1.5, v_num=0]loss embedd 46.1994514465332\n",
      "loss 1.339775800704956\n",
      "Epoch 1:  27%|██▋       | 90/330 [17:55<47:47, 11.95s/it, loss=1.51, v_num=0]loss embedd 57.56432342529297\n",
      "loss 1.7451459169387817\n",
      "Epoch 1:  28%|██▊       | 91/330 [18:07<47:35, 11.95s/it, loss=1.47, v_num=0]loss embedd 51.940921783447266\n",
      "loss 1.4474231004714966\n",
      "Epoch 1:  28%|██▊       | 92/330 [18:19<47:23, 11.95s/it, loss=1.45, v_num=0]loss embedd 52.211082458496094\n",
      "loss 1.175039529800415\n",
      "Epoch 1:  28%|██▊       | 93/330 [18:31<47:11, 11.95s/it, loss=1.43, v_num=0]loss embedd 64.7162857055664\n",
      "loss 1.3196011781692505\n",
      "Epoch 1:  28%|██▊       | 94/330 [18:42<46:59, 11.95s/it, loss=1.41, v_num=0]loss embedd 70.59917449951172\n",
      "loss 1.6242436170578003\n",
      "Epoch 1:  29%|██▉       | 95/330 [18:54<46:47, 11.95s/it, loss=1.42, v_num=0]loss embedd 57.412845611572266\n",
      "loss 1.0433156490325928\n",
      "Epoch 1:  29%|██▉       | 96/330 [19:06<46:35, 11.94s/it, loss=1.4, v_num=0] loss embedd 76.3429946899414\n",
      "loss 1.2685348987579346\n",
      "Epoch 1:  29%|██▉       | 97/330 [19:18<46:23, 11.94s/it, loss=1.39, v_num=0]loss embedd 96.69013977050781\n",
      "loss 1.1697964668273926\n",
      "Epoch 1:  30%|██▉       | 98/330 [19:30<46:10, 11.94s/it, loss=1.37, v_num=0]loss embedd 81.85646057128906\n",
      "loss 1.603275179862976\n",
      "Epoch 1:  30%|███       | 99/330 [19:42<45:58, 11.94s/it, loss=1.36, v_num=0]loss embedd 62.30931854248047\n",
      "loss 1.163960337638855\n",
      "Epoch 1:  30%|███       | 100/330 [19:54<45:46, 11.94s/it, loss=1.35, v_num=0]loss embedd 92.38934326171875\n",
      "loss 1.128720760345459\n",
      "Epoch 1:  31%|███       | 101/330 [20:06<45:34, 11.94s/it, loss=1.35, v_num=0]loss embedd 110.23744201660156\n",
      "loss 1.2369916439056396\n",
      "Epoch 1:  31%|███       | 102/330 [20:18<45:22, 11.94s/it, loss=1.33, v_num=0]loss embedd 96.15474700927734\n",
      "loss 1.1638009548187256\n",
      "Epoch 1:  31%|███       | 103/330 [20:30<45:10, 11.94s/it, loss=1.34, v_num=0]loss embedd 75.0062484741211\n",
      "loss 1.4423307180404663\n",
      "Epoch 1:  32%|███▏      | 104/330 [20:41<44:58, 11.94s/it, loss=1.34, v_num=0]loss embedd 6.220775604248047\n",
      "loss 1.887887716293335\n",
      "Epoch 1:  32%|███▏      | 105/330 [20:53<44:46, 11.94s/it, loss=1.36, v_num=0]loss embedd 3.4556751251220703\n",
      "loss 1.9855295419692993\n",
      "Epoch 1:  32%|███▏      | 106/330 [21:05<44:34, 11.94s/it, loss=1.41, v_num=0]loss embedd 1.8998878002166748\n",
      "loss 1.9915915727615356\n",
      "Epoch 1:  32%|███▏      | 107/330 [21:17<44:22, 11.94s/it, loss=1.44, v_num=0]loss embedd 1.679360032081604\n",
      "loss 2.0291266441345215\n",
      "Epoch 1:  33%|███▎      | 108/330 [21:29<44:10, 11.94s/it, loss=1.47, v_num=0]loss embedd 1.5134586095809937\n",
      "loss 1.9978752136230469\n",
      "Epoch 1:  33%|███▎      | 109/330 [21:41<43:58, 11.94s/it, loss=1.49, v_num=0]loss embedd 1.610746145248413\n",
      "loss 1.998435616493225\n",
      "Epoch 1:  33%|███▎      | 110/330 [21:53<43:46, 11.94s/it, loss=1.52, v_num=0]loss embedd 1.5727818012237549\n",
      "loss 1.9980049133300781\n",
      "Epoch 1:  34%|███▎      | 111/330 [22:05<43:34, 11.94s/it, loss=1.53, v_num=0]loss embedd 1.5979809761047363\n",
      "loss 1.9989323616027832\n",
      "Epoch 1:  34%|███▍      | 112/330 [22:17<43:22, 11.94s/it, loss=1.56, v_num=0]loss embedd 1.452392339706421\n",
      "loss 2.008307933807373\n",
      "Epoch 1:  34%|███▍      | 113/330 [22:29<43:10, 11.94s/it, loss=1.6, v_num=0] loss embedd 1.4901889562606812\n",
      "loss 1.9934788942337036\n",
      "Epoch 1:  35%|███▍      | 114/330 [22:40<42:58, 11.94s/it, loss=1.64, v_num=0]loss embedd 1.5694055557250977\n",
      "loss 1.9968750476837158\n",
      "Epoch 1:  35%|███▍      | 115/330 [22:52<42:46, 11.94s/it, loss=1.66, v_num=0]loss embedd 1.4290204048156738\n",
      "loss 1.9863066673278809\n",
      "Epoch 1:  35%|███▌      | 116/330 [23:04<42:34, 11.94s/it, loss=1.7, v_num=0] loss embedd 1.7436678409576416\n",
      "loss 1.9933172464370728\n",
      "Epoch 1:  35%|███▌      | 117/330 [23:16<42:22, 11.94s/it, loss=1.74, v_num=0]loss embedd 1.8104889392852783\n",
      "loss 1.99146568775177\n",
      "Epoch 1:  36%|███▌      | 118/330 [23:28<42:10, 11.94s/it, loss=1.78, v_num=0]loss embedd 1.8146284818649292\n",
      "loss 1.979642629623413\n",
      "Epoch 1:  36%|███▌      | 119/330 [23:40<41:58, 11.94s/it, loss=1.8, v_num=0] loss embedd 2.1520869731903076\n",
      "loss 1.9936630725860596\n",
      "Epoch 1:  36%|███▋      | 120/330 [23:52<41:46, 11.94s/it, loss=1.84, v_num=0]loss embedd 2.5378870964050293\n",
      "loss 1.9791300296783447\n",
      "Epoch 1:  37%|███▋      | 121/330 [24:04<41:34, 11.94s/it, loss=1.88, v_num=0]loss embedd 2.4089739322662354\n",
      "loss 1.982285976409912\n",
      "Epoch 1:  37%|███▋      | 122/330 [24:16<41:22, 11.93s/it, loss=1.92, v_num=0]loss embedd 2.966834545135498\n",
      "loss 1.9968183040618896\n",
      "Epoch 1:  37%|███▋      | 123/330 [24:28<41:10, 11.94s/it, loss=1.96, v_num=0]loss embedd 2.658348560333252\n",
      "loss 1.9726672172546387\n",
      "Epoch 1:  38%|███▊      | 124/330 [24:40<40:58, 11.94s/it, loss=1.99, v_num=0]loss embedd 3.0950474739074707\n",
      "loss 1.9697232246398926\n",
      "Epoch 1:  38%|███▊      | 125/330 [24:51<40:46, 11.94s/it, loss=1.99, v_num=0]loss embedd 3.1194183826446533\n",
      "loss 1.948691964149475\n",
      "Epoch 1:  38%|███▊      | 126/330 [25:03<40:34, 11.93s/it, loss=1.99, v_num=0]loss embedd 3.6637520790100098\n",
      "loss 1.984292984008789\n",
      "Epoch 1:  38%|███▊      | 127/330 [25:15<40:22, 11.93s/it, loss=1.99, v_num=0]loss embedd 3.171590566635132\n",
      "loss 1.9995150566101074\n",
      "Epoch 1:  39%|███▉      | 128/330 [25:27<40:10, 11.93s/it, loss=1.99, v_num=0]loss embedd 4.141728401184082\n",
      "loss 1.9909536838531494\n",
      "Epoch 1:  39%|███▉      | 129/330 [25:39<39:58, 11.93s/it, loss=1.99, v_num=0]loss embedd 3.9002346992492676\n",
      "loss 1.941056728363037\n",
      "Epoch 1:  39%|███▉      | 130/330 [25:51<39:46, 11.93s/it, loss=1.99, v_num=0]loss embedd 4.780367851257324\n",
      "loss 1.9770901203155518\n",
      "Epoch 1:  40%|███▉      | 131/330 [26:03<39:34, 11.93s/it, loss=1.98, v_num=0]loss embedd 5.25368595123291\n",
      "loss 2.0369510650634766\n",
      "Epoch 1:  40%|████      | 132/330 [26:15<39:22, 11.93s/it, loss=1.99, v_num=0]loss embedd 5.398556709289551\n",
      "loss 2.016925573348999\n",
      "Epoch 1:  40%|████      | 133/330 [26:27<39:10, 11.93s/it, loss=1.99, v_num=0]loss embedd 6.825919151306152\n",
      "loss 1.9801669120788574\n",
      "Epoch 1:  41%|████      | 134/330 [26:38<38:58, 11.93s/it, loss=1.99, v_num=0]loss embedd 7.352618217468262\n",
      "loss 2.008962392807007\n",
      "Epoch 1:  41%|████      | 135/330 [26:50<38:46, 11.93s/it, loss=1.99, v_num=0]loss embedd 5.920344352722168\n",
      "loss 1.947709083557129\n",
      "Epoch 1:  41%|████      | 136/330 [27:02<38:35, 11.93s/it, loss=1.98, v_num=0]loss embedd 3.9047646522521973\n",
      "loss 1.9855846166610718\n",
      "Epoch 1:  42%|████▏     | 137/330 [27:14<38:23, 11.93s/it, loss=1.98, v_num=0]loss embedd 4.16108512878418\n",
      "loss 1.9466933012008667\n",
      "Epoch 1:  42%|████▏     | 138/330 [27:26<38:11, 11.93s/it, loss=1.98, v_num=0]loss embedd 4.6567277908325195\n",
      "loss 1.981128454208374\n",
      "Epoch 1:  42%|████▏     | 139/330 [27:40<38:01, 11.94s/it, loss=1.98, v_num=0]loss embedd 5.690842151641846\n",
      "loss 1.9817405939102173\n",
      "Epoch 1:  42%|████▏     | 140/330 [27:52<37:49, 11.94s/it, loss=1.98, v_num=0]loss embedd 4.54180908203125\n",
      "loss 2.0097239017486572\n",
      "Epoch 1:  43%|████▎     | 141/330 [28:04<37:37, 11.95s/it, loss=1.98, v_num=0]loss embedd 3.686779022216797\n",
      "loss 2.0320560932159424\n",
      "Epoch 1:  43%|████▎     | 142/330 [28:16<37:26, 11.95s/it, loss=1.99, v_num=0]loss embedd 2.7690486907958984\n",
      "loss 2.0333328247070312\n",
      "Epoch 1:  43%|████▎     | 143/330 [28:28<37:14, 11.95s/it, loss=1.99, v_num=0]loss embedd 3.1069259643554688\n",
      "loss 2.0153183937072754\n",
      "Epoch 1:  44%|████▎     | 144/330 [28:40<37:02, 11.95s/it, loss=1.99, v_num=0]loss embedd 2.3389575481414795\n",
      "loss 1.9828855991363525\n",
      "Epoch 1:  44%|████▍     | 145/330 [28:52<36:50, 11.95s/it, loss=1.99, v_num=0]loss embedd 3.1986889839172363\n",
      "loss 2.0346426963806152\n",
      "Epoch 1:  44%|████▍     | 146/330 [29:04<36:38, 11.95s/it, loss=1.99, v_num=0]loss embedd 2.236039400100708\n",
      "loss 2.0022025108337402\n",
      "Epoch 1:  45%|████▍     | 147/330 [29:16<36:27, 11.95s/it, loss=2, v_num=0]   loss embedd 2.2117576599121094\n",
      "loss 2.011538028717041\n",
      "Epoch 1:  45%|████▍     | 148/330 [29:28<36:15, 11.95s/it, loss=2, v_num=0]loss embedd 2.1917991638183594\n",
      "loss 1.9997152090072632\n",
      "Epoch 1:  45%|████▌     | 149/330 [29:41<36:03, 11.95s/it, loss=2, v_num=0]loss embedd 2.1756093502044678\n",
      "loss 2.002171516418457\n",
      "Epoch 1:  45%|████▌     | 150/330 [29:53<35:51, 11.95s/it, loss=2, v_num=0]loss embedd 2.161374807357788\n",
      "loss 1.9994069337844849\n",
      "Epoch 1:  46%|████▌     | 151/330 [30:05<35:39, 11.96s/it, loss=2, v_num=0]loss embedd 2.151413917541504\n",
      "loss 2.002152681350708\n",
      "Epoch 1:  46%|████▌     | 152/330 [30:17<35:28, 11.96s/it, loss=2, v_num=0]loss embedd 2.1476495265960693\n",
      "loss 2.0021462440490723\n",
      "Epoch 1:  46%|████▋     | 153/330 [30:29<35:16, 11.96s/it, loss=2, v_num=0]loss embedd 2.1354517936706543\n",
      "loss 2.0021326541900635\n",
      "Epoch 1:  47%|████▋     | 154/330 [30:41<35:04, 11.96s/it, loss=2, v_num=0]loss embedd 2.12861704826355\n",
      "loss 2.0021321773529053\n",
      "Epoch 1:  47%|████▋     | 155/330 [30:53<34:52, 11.96s/it, loss=2, v_num=0]loss embedd 2.129166841506958\n",
      "loss 2.002134084701538\n",
      "Epoch 1:  47%|████▋     | 156/330 [31:05<34:40, 11.96s/it, loss=2, v_num=0]loss embedd 2.1291651725769043\n",
      "loss 2.002131938934326\n",
      "Epoch 1:  48%|████▊     | 157/330 [31:17<34:29, 11.96s/it, loss=2, v_num=0]loss embedd 2.130568265914917\n",
      "loss 2.0021238327026367\n",
      "Epoch 1:  48%|████▊     | 158/330 [31:29<34:17, 11.96s/it, loss=2.01, v_num=0]loss embedd 2.1257574558258057\n",
      "loss 2.0021274089813232\n",
      "Epoch 1:  48%|████▊     | 159/330 [31:42<34:05, 11.96s/it, loss=2.01, v_num=0]loss embedd 2.120210647583008\n",
      "loss 2.0021212100982666\n",
      "Epoch 1:  48%|████▊     | 160/330 [31:54<33:53, 11.96s/it, loss=2.01, v_num=0]loss embedd 2.123684883117676\n",
      "loss 2.002120018005371\n",
      "Epoch 1:  49%|████▉     | 161/330 [32:06<33:41, 11.96s/it, loss=2.01, v_num=0]loss embedd 2.1298859119415283\n",
      "loss 2.0021228790283203\n",
      "Epoch 1:  49%|████▉     | 162/330 [32:18<33:30, 11.96s/it, loss=2.01, v_num=0]loss embedd 2.1374752521514893\n",
      "loss 2.0021395683288574\n",
      "Epoch 1:  49%|████▉     | 163/330 [32:30<33:18, 11.97s/it, loss=2, v_num=0]   loss embedd 2.173811197280884\n",
      "loss 2.002166986465454\n",
      "Epoch 1:  50%|████▉     | 164/330 [32:42<33:06, 11.97s/it, loss=2, v_num=0]loss embedd 2.3108201026916504\n",
      "loss 2.0023388862609863\n",
      "Epoch 1:  50%|█████     | 165/330 [32:54<32:54, 11.97s/it, loss=2, v_num=0]loss embedd 2.547563076019287\n",
      "loss 2.0025057792663574\n",
      "Epoch 1:  50%|█████     | 166/330 [33:06<32:42, 11.97s/it, loss=2, v_num=0]loss embedd 2.855475425720215\n",
      "loss 2.002819776535034\n",
      "Epoch 1:  51%|█████     | 167/330 [33:18<32:30, 11.97s/it, loss=2, v_num=0]loss embedd 3.2014660835266113\n",
      "loss 2.0031957626342773\n",
      "Epoch 1:  51%|█████     | 168/330 [33:30<32:18, 11.97s/it, loss=2, v_num=0]loss embedd 3.5440611839294434\n",
      "loss 2.003493547439575\n",
      "Epoch 1:  51%|█████     | 169/330 [33:42<32:06, 11.97s/it, loss=2, v_num=0]loss embedd 3.8496975898742676\n",
      "loss 2.003836154937744\n",
      "Epoch 1:  52%|█████▏    | 170/330 [33:54<31:54, 11.97s/it, loss=2, v_num=0]loss embedd 4.099763870239258\n",
      "loss 2.0041375160217285\n",
      "Epoch 1:  52%|█████▏    | 171/330 [34:06<31:42, 11.97s/it, loss=2, v_num=0]loss embedd 4.2410736083984375\n",
      "loss 2.0042407512664795\n",
      "Epoch 1:  52%|█████▏    | 172/330 [34:18<31:30, 11.97s/it, loss=2, v_num=0]loss embedd 4.315166473388672\n",
      "loss 2.004348039627075\n",
      "Epoch 1:  52%|█████▏    | 173/330 [34:29<31:18, 11.97s/it, loss=2, v_num=0]loss embedd 4.33107328414917\n",
      "loss 2.00431752204895\n",
      "Epoch 1:  53%|█████▎    | 174/330 [34:41<31:06, 11.97s/it, loss=2, v_num=0]loss embedd 4.286499977111816\n",
      "loss 2.0042884349823\n",
      "Epoch 1:  53%|█████▎    | 175/330 [34:53<30:54, 11.97s/it, loss=2, v_num=0]loss embedd 4.187270164489746\n",
      "loss 2.00422739982605\n",
      "Epoch 1:  53%|█████▎    | 176/330 [35:05<30:42, 11.96s/it, loss=2, v_num=0]loss embedd 4.03982400894165\n",
      "loss 2.0040721893310547\n",
      "Epoch 1:  54%|█████▎    | 177/330 [35:17<30:30, 11.96s/it, loss=2, v_num=0]loss embedd 3.8601629734039307\n",
      "loss 2.0038557052612305\n",
      "Epoch 1:  54%|█████▍    | 178/330 [35:29<30:18, 11.97s/it, loss=2, v_num=0]loss embedd 3.6671814918518066\n",
      "loss 2.0035414695739746\n",
      "Epoch 1:  54%|█████▍    | 179/330 [35:41<30:06, 11.97s/it, loss=2, v_num=0]loss embedd 3.523378372192383\n",
      "loss 2.0035223960876465\n",
      "Epoch 1:  55%|█████▍    | 180/330 [35:53<29:54, 11.96s/it, loss=2, v_num=0]loss embedd 3.4096364974975586\n",
      "loss 2.0034005641937256\n",
      "Epoch 1:  55%|█████▍    | 181/330 [36:05<29:42, 11.96s/it, loss=2, v_num=0]loss embedd 3.2829103469848633\n",
      "loss 2.003272294998169\n",
      "Epoch 1:  55%|█████▌    | 182/330 [36:17<29:30, 11.96s/it, loss=2, v_num=0]loss embedd 3.140744686126709\n",
      "loss 2.0031425952911377\n",
      "Epoch 1:  55%|█████▌    | 183/330 [36:29<29:18, 11.96s/it, loss=2, v_num=0]loss embedd 3.0266590118408203\n",
      "loss 2.0030224323272705\n",
      "Epoch 1:  56%|█████▌    | 184/330 [36:41<29:06, 11.96s/it, loss=2, v_num=0]loss embedd 2.9145944118499756\n",
      "loss 2.002915620803833\n",
      "Epoch 1:  56%|█████▌    | 185/330 [36:53<28:54, 11.96s/it, loss=2, v_num=0]loss embedd 2.8024399280548096\n",
      "loss 2.002793550491333\n",
      "Epoch 1:  56%|█████▋    | 186/330 [37:05<28:42, 11.96s/it, loss=2, v_num=0]loss embedd 2.689727306365967\n",
      "loss 2.0027055740356445\n",
      "Epoch 1:  57%|█████▋    | 187/330 [37:17<28:30, 11.96s/it, loss=2, v_num=0]loss embedd 2.577521324157715\n",
      "loss 2.0025925636291504\n",
      "Epoch 1:  57%|█████▋    | 188/330 [37:29<28:18, 11.96s/it, loss=2, v_num=0]loss embedd 2.464268445968628\n",
      "loss 2.002485990524292\n",
      "Epoch 1:  57%|█████▋    | 189/330 [37:41<28:06, 11.96s/it, loss=2, v_num=0]loss embedd 2.353787660598755\n",
      "loss 2.0023438930511475\n",
      "Epoch 1:  58%|█████▊    | 190/330 [37:52<27:54, 11.96s/it, loss=2, v_num=0]loss embedd 2.250492572784424\n",
      "loss 2.0022311210632324\n",
      "Epoch 1:  58%|█████▊    | 191/330 [38:05<27:42, 11.96s/it, loss=2, v_num=0]loss embedd 2.1603915691375732\n",
      "loss 2.0021448135375977\n",
      "Epoch 1:  58%|█████▊    | 192/330 [38:16<27:30, 11.96s/it, loss=2, v_num=0]loss embedd 2.0869827270507812\n",
      "loss 2.002103805541992\n",
      "Epoch 1:  58%|█████▊    | 193/330 [38:28<27:18, 11.96s/it, loss=2, v_num=0]loss embedd 2.0272674560546875\n",
      "loss 2.0020203590393066\n",
      "Epoch 1:  59%|█████▉    | 194/330 [38:40<27:06, 11.96s/it, loss=2, v_num=0]loss embedd 1.9821040630340576\n",
      "loss 2.001990795135498\n",
      "Epoch 1:  59%|█████▉    | 195/330 [38:52<26:54, 11.96s/it, loss=2, v_num=0]loss embedd 1.950881838798523\n",
      "loss 2.001972198486328\n",
      "Epoch 1:  59%|█████▉    | 196/330 [39:04<26:42, 11.96s/it, loss=2, v_num=0]loss embedd 1.931472659111023\n",
      "loss 2.0018975734710693\n",
      "Epoch 1:  60%|█████▉    | 197/330 [39:16<26:30, 11.96s/it, loss=2, v_num=0]loss embedd 1.9225070476531982\n",
      "loss 2.0019149780273438\n",
      "Epoch 1:  60%|██████    | 198/330 [39:28<26:18, 11.96s/it, loss=2, v_num=0]loss embedd 1.9244155883789062\n",
      "loss 2.001922130584717\n",
      "Epoch 1:  60%|██████    | 199/330 [39:40<26:06, 11.96s/it, loss=2, v_num=0]loss embedd 1.9299191236495972\n",
      "loss 2.001926898956299\n",
      "Epoch 1:  61%|██████    | 200/330 [39:52<25:54, 11.96s/it, loss=2, v_num=0]loss embedd 1.9358985424041748\n",
      "loss 2.0019359588623047\n",
      "Epoch 1:  61%|██████    | 201/330 [40:04<25:42, 11.96s/it, loss=2, v_num=0]loss embedd 1.9416472911834717\n",
      "loss 2.0019359588623047\n",
      "Epoch 1:  61%|██████    | 202/330 [40:15<25:30, 11.96s/it, loss=2, v_num=0]loss embedd 1.9510838985443115\n",
      "loss 2.00193452835083\n",
      "Epoch 1:  62%|██████▏   | 203/330 [40:27<25:18, 11.96s/it, loss=2, v_num=0]loss embedd 1.9566140174865723\n",
      "loss 2.001967191696167\n",
      "Epoch 1:  62%|██████▏   | 204/330 [40:39<25:06, 11.96s/it, loss=2, v_num=0]loss embedd 1.9638447761535645\n",
      "loss 2.0019631385803223\n",
      "Epoch 1:  62%|██████▏   | 205/330 [40:51<24:54, 11.96s/it, loss=2, v_num=0]loss embedd 1.9704333543777466\n",
      "loss 2.0019726753234863\n",
      "Epoch 1:  62%|██████▏   | 206/330 [41:03<24:42, 11.96s/it, loss=2, v_num=0]loss embedd 1.9795069694519043\n",
      "loss 2.0019752979278564\n",
      "Epoch 1:  63%|██████▎   | 207/330 [41:15<24:30, 11.96s/it, loss=2, v_num=0]loss embedd 1.9898402690887451\n",
      "loss 2.001990556716919\n",
      "Epoch 1:  63%|██████▎   | 208/330 [41:27<24:18, 11.96s/it, loss=2, v_num=0]loss embedd 1.9994702339172363\n",
      "loss 2.001999855041504\n",
      "Epoch 1:  63%|██████▎   | 209/330 [41:39<24:06, 11.96s/it, loss=2, v_num=0]loss embedd 2.0071239471435547\n",
      "loss 2.0020062923431396\n",
      "Epoch 1:  64%|██████▎   | 210/330 [41:51<23:55, 11.96s/it, loss=2, v_num=0]loss embedd 2.014301300048828\n",
      "loss 2.0019783973693848\n",
      "Epoch 1:  64%|██████▍   | 211/330 [42:03<23:43, 11.96s/it, loss=2, v_num=0]loss embedd 2.021690845489502\n",
      "loss 2.003089427947998\n",
      "Epoch 1:  64%|██████▍   | 212/330 [42:15<23:31, 11.96s/it, loss=2, v_num=0]loss embedd 2.0266072750091553\n",
      "loss 2.0020217895507812\n",
      "Epoch 1:  65%|██████▍   | 213/330 [42:27<23:19, 11.96s/it, loss=2, v_num=0]loss embedd 2.0291056632995605\n",
      "loss 2.002011299133301\n",
      "Epoch 1:  65%|██████▍   | 214/330 [42:39<23:07, 11.96s/it, loss=2, v_num=0]loss embedd 2.0337014198303223\n",
      "loss 2.0020058155059814\n",
      "Epoch 1:  65%|██████▌   | 215/330 [42:51<22:55, 11.96s/it, loss=2, v_num=0]loss embedd 2.032315731048584\n",
      "loss 2.002032995223999\n",
      "Epoch 1:  65%|██████▌   | 216/330 [43:03<22:43, 11.96s/it, loss=2, v_num=0]loss embedd 2.031256914138794\n",
      "loss 2.0020298957824707\n",
      "Epoch 1:  66%|██████▌   | 217/330 [43:15<22:31, 11.96s/it, loss=2, v_num=0]loss embedd 2.029942750930786\n",
      "loss 2.00203275680542\n",
      "Epoch 1:  66%|██████▌   | 218/330 [43:26<22:19, 11.96s/it, loss=2, v_num=0]loss embedd 2.02598237991333\n",
      "loss 2.0020289421081543\n",
      "Epoch 1:  66%|██████▋   | 219/330 [43:38<22:07, 11.96s/it, loss=2, v_num=0]loss embedd 2.018939733505249\n",
      "loss 2.002018928527832\n",
      "Epoch 1:  67%|██████▋   | 220/330 [43:50<21:55, 11.96s/it, loss=2, v_num=0]loss embedd 2.0097720623016357\n",
      "loss 2.0020079612731934\n",
      "Epoch 1:  67%|██████▋   | 221/330 [44:02<21:43, 11.96s/it, loss=2, v_num=0]loss embedd 1.9977846145629883\n",
      "loss 2.0019989013671875\n",
      "Epoch 1:  67%|██████▋   | 222/330 [44:14<21:31, 11.96s/it, loss=2, v_num=0]loss embedd 1.9818756580352783\n",
      "loss 2.001988649368286\n",
      "Epoch 1:  68%|██████▊   | 223/330 [44:26<21:19, 11.96s/it, loss=2, v_num=0]loss embedd 1.9644174575805664\n",
      "loss 2.001970052719116\n",
      "Epoch 1:  68%|██████▊   | 224/330 [44:38<21:07, 11.96s/it, loss=2, v_num=0]loss embedd 1.9603421688079834\n",
      "loss 2.001960277557373\n",
      "Epoch 1:  68%|██████▊   | 225/330 [44:50<20:55, 11.96s/it, loss=2, v_num=0]loss embedd 1.9541062116622925\n",
      "loss 2.0019493103027344\n",
      "Epoch 1:  68%|██████▊   | 226/330 [45:02<20:43, 11.96s/it, loss=2, v_num=0]loss embedd 1.9423282146453857\n",
      "loss 2.0019490718841553\n",
      "Epoch 1:  69%|██████▉   | 227/330 [45:14<20:31, 11.96s/it, loss=2, v_num=0]loss embedd 1.9244740009307861\n",
      "loss 2.001917600631714\n",
      "Epoch 1:  69%|██████▉   | 228/330 [45:26<20:19, 11.96s/it, loss=2, v_num=0]loss embedd 1.8999214172363281\n",
      "loss 2.0019075870513916\n",
      "Epoch 1:  69%|██████▉   | 229/330 [45:37<20:07, 11.96s/it, loss=2, v_num=0]loss embedd 1.8690555095672607\n",
      "loss 2.0018603801727295\n",
      "Epoch 1:  70%|██████▉   | 230/330 [45:50<19:55, 11.96s/it, loss=2, v_num=0]loss embedd 1.832432746887207\n",
      "loss 2.001847505569458\n",
      "Epoch 1:  70%|███████   | 231/330 [46:01<19:43, 11.96s/it, loss=2, v_num=0]loss embedd 1.7915711402893066\n",
      "loss 2.001791477203369\n",
      "Epoch 1:  70%|███████   | 232/330 [46:13<19:31, 11.96s/it, loss=2, v_num=0]loss embedd 1.7490146160125732\n",
      "loss 2.001753568649292\n",
      "Epoch 1:  71%|███████   | 233/330 [46:25<19:19, 11.96s/it, loss=2, v_num=0]loss embedd 1.7031960487365723\n",
      "loss 2.0016965866088867\n",
      "Epoch 1:  71%|███████   | 234/330 [46:37<19:07, 11.96s/it, loss=2, v_num=0]loss embedd 1.6634540557861328\n",
      "loss 2.0016634464263916\n",
      "Epoch 1:  71%|███████   | 235/330 [46:49<18:55, 11.96s/it, loss=2, v_num=0]loss embedd 1.6296377182006836\n",
      "loss 2.001629590988159\n",
      "Epoch 1:  72%|███████▏  | 236/330 [47:01<18:43, 11.96s/it, loss=2, v_num=0]loss embedd 1.5954174995422363\n",
      "loss 2.0015954971313477\n",
      "Epoch 1:  72%|███████▏  | 237/330 [47:13<18:31, 11.96s/it, loss=2, v_num=0]loss embedd 1.5591899156570435\n",
      "loss 2.001559257507324\n",
      "Epoch 1:  72%|███████▏  | 238/330 [47:25<18:19, 11.96s/it, loss=2, v_num=0]loss embedd 1.5388085842132568\n",
      "loss 2.0015387535095215\n",
      "Epoch 1:  72%|███████▏  | 239/330 [47:37<18:07, 11.96s/it, loss=2, v_num=0]loss embedd 1.5309380292892456\n",
      "loss 2.001530885696411\n",
      "Epoch 1:  73%|███████▎  | 240/330 [47:49<17:55, 11.95s/it, loss=2, v_num=0]loss embedd 1.5239384174346924\n",
      "loss 2.001523971557617\n",
      "Epoch 1:  73%|███████▎  | 241/330 [48:01<17:43, 11.95s/it, loss=2, v_num=0]loss embedd 1.5170438289642334\n",
      "loss 2.001516580581665\n",
      "Epoch 1:  73%|███████▎  | 242/330 [48:13<17:32, 11.95s/it, loss=2, v_num=0]loss embedd 1.5129436254501343\n",
      "loss 2.0015130043029785\n",
      "Epoch 1:  74%|███████▎  | 243/330 [48:24<17:20, 11.95s/it, loss=2, v_num=0]loss embedd 1.507770299911499\n",
      "loss 2.0015077590942383\n",
      "Epoch 1:  74%|███████▍  | 244/330 [48:36<17:08, 11.95s/it, loss=2, v_num=0]loss embedd 1.5011405944824219\n",
      "loss 2.0015010833740234\n",
      "Epoch 1:  74%|███████▍  | 245/330 [48:48<16:56, 11.95s/it, loss=2, v_num=0]loss embedd 1.4937503337860107\n",
      "loss 2.0014936923980713\n",
      "Epoch 1:  75%|███████▍  | 246/330 [49:00<16:44, 11.95s/it, loss=2, v_num=0]loss embedd 1.4865672588348389\n",
      "loss 2.0014865398406982\n",
      "Epoch 1:  75%|███████▍  | 247/330 [49:12<16:32, 11.95s/it, loss=2, v_num=0]loss embedd 1.478816032409668\n",
      "loss 2.001478910446167\n",
      "Epoch 1:  75%|███████▌  | 248/330 [49:24<16:20, 11.95s/it, loss=2, v_num=0]loss embedd 1.4707520008087158\n",
      "loss 2.0014708042144775\n",
      "Epoch 1:  75%|███████▌  | 249/330 [49:36<16:08, 11.95s/it, loss=2, v_num=0]loss embedd 1.4609605073928833\n",
      "loss 2.0014610290527344\n",
      "Epoch 1:  76%|███████▌  | 250/330 [49:48<15:56, 11.95s/it, loss=2, v_num=0]loss embedd 1.4497731924057007\n",
      "loss 2.0014498233795166\n",
      "Epoch 1:  76%|███████▌  | 251/330 [50:00<15:44, 11.95s/it, loss=2, v_num=0]loss embedd 1.436810851097107\n",
      "loss 2.001436710357666\n",
      "Epoch 1:  76%|███████▋  | 252/330 [50:12<15:32, 11.95s/it, loss=2, v_num=0]loss embedd 1.4224600791931152\n",
      "loss 2.00142240524292\n",
      "Epoch 1:  77%|███████▋  | 253/330 [50:24<15:20, 11.95s/it, loss=2, v_num=0]loss embedd 1.4062752723693848\n",
      "loss 2.001406192779541\n",
      "Epoch 1:  77%|███████▋  | 254/330 [50:36<15:08, 11.95s/it, loss=2, v_num=0]loss embedd 1.387969732284546\n",
      "loss 2.0013880729675293\n",
      "Epoch 1:  77%|███████▋  | 255/330 [50:48<14:56, 11.95s/it, loss=2, v_num=0]loss embedd 1.3677979707717896\n",
      "loss 2.0013678073883057\n",
      "Epoch 1:  78%|███████▊  | 256/330 [51:00<14:44, 11.95s/it, loss=2, v_num=0]loss embedd 1.3461461067199707\n",
      "loss 2.0013461112976074\n",
      "Epoch 1:  78%|███████▊  | 257/330 [51:12<14:32, 11.95s/it, loss=2, v_num=0]loss embedd 1.3227307796478271\n",
      "loss 2.0013227462768555\n",
      "Epoch 1:  78%|███████▊  | 258/330 [51:24<14:20, 11.95s/it, loss=2, v_num=0]loss embedd 1.2973575592041016\n",
      "loss 2.0012974739074707\n",
      "Epoch 1:  78%|███████▊  | 259/330 [51:36<14:08, 11.95s/it, loss=2, v_num=0]loss embedd 1.2700629234313965\n",
      "loss 2.001270055770874\n",
      "Epoch 1:  79%|███████▉  | 260/330 [51:48<13:56, 11.95s/it, loss=2, v_num=0]loss embedd 1.2406448125839233\n",
      "loss 2.0012407302856445\n",
      "Epoch 1:  79%|███████▉  | 261/330 [52:00<13:44, 11.95s/it, loss=2, v_num=0]loss embedd 1.2096518278121948\n",
      "loss 2.0012097358703613\n",
      "Epoch 1:  79%|███████▉  | 262/330 [52:12<13:32, 11.95s/it, loss=2, v_num=0]loss embedd 1.1782218217849731\n",
      "loss 2.00117826461792\n",
      "Epoch 1:  80%|███████▉  | 263/330 [52:24<13:20, 11.95s/it, loss=2, v_num=0]loss embedd 1.1455076932907104\n",
      "loss 2.001145601272583\n",
      "Epoch 1:  80%|████████  | 264/330 [52:35<13:08, 11.95s/it, loss=2, v_num=0]loss embedd 1.1122394800186157\n",
      "loss 2.001112222671509\n",
      "Epoch 1:  80%|████████  | 265/330 [52:47<12:57, 11.95s/it, loss=2, v_num=0]loss embedd 1.0780458450317383\n",
      "loss 2.0010781288146973\n",
      "Epoch 1:  81%|████████  | 266/330 [52:59<12:45, 11.95s/it, loss=2, v_num=0]loss embedd 1.0444297790527344\n",
      "loss 2.001044511795044\n",
      "Epoch 1:  81%|████████  | 267/330 [53:11<12:33, 11.95s/it, loss=2, v_num=0]loss embedd 1.0130616426467896\n",
      "loss 2.0010130405426025\n",
      "Epoch 1:  81%|████████  | 268/330 [53:23<12:21, 11.95s/it, loss=2, v_num=0]loss embedd 0.9825109243392944\n",
      "loss 2.0009825229644775\n",
      "Epoch 1:  82%|████████▏ | 269/330 [53:35<12:09, 11.95s/it, loss=2, v_num=0]loss embedd 0.9525716304779053\n",
      "loss 2.0009524822235107\n",
      "Epoch 1:  82%|████████▏ | 270/330 [53:47<11:57, 11.95s/it, loss=2, v_num=0]loss embedd 0.9229899644851685\n",
      "loss 2.000922918319702\n",
      "Epoch 1:  82%|████████▏ | 271/330 [53:59<11:45, 11.95s/it, loss=2, v_num=0]loss embedd 0.8951258659362793\n",
      "loss 2.0008950233459473\n",
      "Epoch 1:  82%|████████▏ | 272/330 [54:11<11:33, 11.95s/it, loss=2, v_num=0]loss embedd 0.8707073926925659\n",
      "loss 2.000870704650879\n",
      "Epoch 1:  83%|████████▎ | 273/330 [54:23<11:21, 11.95s/it, loss=2, v_num=0]loss embedd 0.846605658531189\n",
      "loss 2.0008466243743896\n",
      "Epoch 1:  83%|████████▎ | 274/330 [54:35<11:09, 11.95s/it, loss=2, v_num=0]loss embedd 0.8219491243362427\n",
      "loss 2.000822067260742\n",
      "Epoch 1:  83%|████████▎ | 275/330 [54:47<10:57, 11.95s/it, loss=2, v_num=0]loss embedd 0.7969505786895752\n",
      "loss 2.0007970333099365\n",
      "Epoch 1:  84%|████████▎ | 276/330 [54:59<10:45, 11.95s/it, loss=2, v_num=0]loss embedd 0.7716699838638306\n",
      "loss 2.0007717609405518\n",
      "Epoch 1:  84%|████████▍ | 277/330 [55:11<10:33, 11.95s/it, loss=2, v_num=0]loss embedd 0.7466857433319092\n",
      "loss 2.000746726989746\n",
      "Epoch 1:  84%|████████▍ | 278/330 [55:22<10:21, 11.95s/it, loss=2, v_num=0]loss embedd 0.722709596157074\n",
      "loss 2.000722646713257\n",
      "Epoch 1:  85%|████████▍ | 279/330 [55:34<10:09, 11.95s/it, loss=2, v_num=0]loss embedd 0.6995622515678406\n",
      "loss 2.000699520111084\n",
      "Epoch 1:  85%|████████▍ | 280/330 [55:46<09:57, 11.95s/it, loss=2, v_num=0]loss embedd 0.6771132349967957\n",
      "loss 2.0006771087646484\n",
      "Epoch 1:  85%|████████▌ | 281/330 [55:58<09:45, 11.95s/it, loss=2, v_num=0]loss embedd 0.6556392908096313\n",
      "loss 2.0006556510925293\n",
      "Epoch 1:  85%|████████▌ | 282/330 [56:10<09:33, 11.95s/it, loss=2, v_num=0]loss embedd 0.6354317665100098\n",
      "loss 2.0006353855133057\n",
      "Epoch 1:  86%|████████▌ | 283/330 [56:22<09:21, 11.95s/it, loss=2, v_num=0]loss embedd 0.6169434785842896\n",
      "loss 2.000617027282715\n",
      "Epoch 1:  86%|████████▌ | 284/330 [56:34<09:09, 11.95s/it, loss=2, v_num=0]loss embedd 0.6024273633956909\n",
      "loss 2.0006024837493896\n",
      "Epoch 1:  86%|████████▋ | 285/330 [56:46<08:57, 11.95s/it, loss=2, v_num=0]loss embedd 0.5897337794303894\n",
      "loss 2.0005898475646973\n",
      "Epoch 1:  87%|████████▋ | 286/330 [56:58<08:45, 11.95s/it, loss=2, v_num=0]loss embedd 0.5794090032577515\n",
      "loss 2.000579357147217\n",
      "Epoch 1:  87%|████████▋ | 287/330 [57:09<08:33, 11.95s/it, loss=2, v_num=0]loss embedd 0.5701003670692444\n",
      "loss 2.000570058822632\n",
      "Epoch 1:  87%|████████▋ | 288/330 [57:21<08:21, 11.95s/it, loss=2, v_num=0]loss embedd 0.5623007416725159\n",
      "loss 2.0005621910095215\n",
      "Epoch 1:  88%|████████▊ | 289/330 [57:33<08:09, 11.95s/it, loss=2, v_num=0]loss embedd 0.5554174184799194\n",
      "loss 2.0005555152893066\n",
      "Epoch 1:  88%|████████▊ | 290/330 [57:45<07:58, 11.95s/it, loss=2, v_num=0]loss embedd 0.5493613481521606\n",
      "loss 2.00054931640625\n",
      "Epoch 1:  88%|████████▊ | 291/330 [57:57<07:46, 11.95s/it, loss=2, v_num=0]loss embedd 0.5441481471061707\n",
      "loss 2.0005440711975098\n",
      "Epoch 1:  88%|████████▊ | 292/330 [58:09<07:34, 11.95s/it, loss=2, v_num=0]loss embedd 0.5397723913192749\n",
      "loss 2.000539779663086\n",
      "Epoch 1:  89%|████████▉ | 293/330 [58:21<07:22, 11.95s/it, loss=2, v_num=0]loss embedd 0.5361535549163818\n",
      "loss 2.0005362033843994\n",
      "Epoch 1:  89%|████████▉ | 294/330 [58:33<07:10, 11.95s/it, loss=2, v_num=0]loss embedd 0.5329200029373169\n",
      "loss 2.000532865524292\n",
      "Epoch 1:  89%|████████▉ | 295/330 [58:45<06:58, 11.95s/it, loss=2, v_num=0]loss embedd 0.5297898650169373\n",
      "loss 2.0005297660827637\n",
      "Epoch 1:  90%|████████▉ | 296/330 [58:57<06:46, 11.95s/it, loss=2, v_num=0]loss embedd 0.526777982711792\n",
      "loss 2.0005266666412354\n",
      "Epoch 1:  90%|█████████ | 297/330 [59:09<06:34, 11.95s/it, loss=2, v_num=0]loss embedd 0.5238804221153259\n",
      "loss 2.000523805618286\n",
      "Epoch 1:  90%|█████████ | 298/330 [59:21<06:22, 11.95s/it, loss=2, v_num=0]loss embedd 0.5210884213447571\n",
      "loss 2.000521183013916\n",
      "Epoch 1:  91%|█████████ | 299/330 [59:33<06:10, 11.95s/it, loss=2, v_num=0]loss embedd 0.5184080004692078\n",
      "loss 2.000518321990967\n",
      "Epoch 1:  91%|█████████ | 300/330 [59:46<05:58, 11.95s/it, loss=2, v_num=0]loss embedd 0.5158374309539795\n",
      "loss 2.000515937805176\n",
      "Epoch 1:  91%|█████████ | 301/330 [59:58<05:46, 11.95s/it, loss=2, v_num=0]loss embedd 0.5133810043334961\n",
      "loss 2.0005133152008057\n",
      "Epoch 1:  92%|█████████▏| 302/330 [1:00:10<05:34, 11.95s/it, loss=2, v_num=0]loss embedd 0.5110361576080322\n",
      "loss 2.0005109310150146\n",
      "Epoch 1:  92%|█████████▏| 303/330 [1:00:22<05:22, 11.95s/it, loss=2, v_num=0]loss embedd 0.5088346004486084\n",
      "loss 2.0005087852478027\n",
      "Epoch 1:  92%|█████████▏| 304/330 [1:00:34<05:10, 11.95s/it, loss=2, v_num=0]loss embedd 0.5068761706352234\n",
      "loss 2.00050687789917\n",
      "Epoch 1:  92%|█████████▏| 305/330 [1:00:46<04:58, 11.95s/it, loss=2, v_num=0]loss embedd 0.5050421953201294\n",
      "loss 2.000504970550537\n",
      "Epoch 1:  93%|█████████▎| 306/330 [1:00:57<04:46, 11.95s/it, loss=2, v_num=0]loss embedd 0.5031349062919617\n",
      "loss 2.0005030632019043\n",
      "Epoch 1:  93%|█████████▎| 307/330 [1:01:09<04:34, 11.95s/it, loss=2, v_num=0]loss embedd 0.501030683517456\n",
      "loss 2.0005009174346924\n",
      "Epoch 1:  93%|█████████▎| 308/330 [1:01:21<04:22, 11.95s/it, loss=2, v_num=0]loss embedd 0.4989282488822937\n",
      "loss 2.0004990100860596\n",
      "Epoch 1:  94%|█████████▎| 309/330 [1:01:33<04:11, 11.95s/it, loss=2, v_num=0]loss embedd 0.4968084990978241\n",
      "loss 2.0004968643188477\n",
      "Epoch 1:  94%|█████████▍| 310/330 [1:01:45<03:59, 11.95s/it, loss=2, v_num=0]loss embedd 0.4946519732475281\n",
      "loss 2.0004947185516357\n",
      "Epoch 1:  94%|█████████▍| 311/330 [1:01:58<03:47, 11.96s/it, loss=2, v_num=0]loss embedd 0.4927101731300354\n",
      "loss 2.000492811203003\n",
      "Epoch 1:  95%|█████████▍| 312/330 [1:02:09<03:35, 11.95s/it, loss=2, v_num=0]loss embedd 0.4907143712043762\n",
      "loss 2.000490665435791\n",
      "Epoch 1:  95%|█████████▍| 313/330 [1:02:22<03:23, 11.96s/it, loss=2, v_num=0]loss embedd 0.4886813163757324\n",
      "loss 2.000488758087158\n",
      "Epoch 1:  95%|█████████▌| 314/330 [1:02:34<03:11, 11.96s/it, loss=2, v_num=0]loss embedd 0.48665812611579895\n",
      "loss 2.0004866123199463\n",
      "Epoch 1:  95%|█████████▌| 315/330 [1:02:46<02:59, 11.96s/it, loss=2, v_num=0]loss embedd 0.4847811460494995\n",
      "loss 2.0004847049713135\n",
      "Epoch 1:  96%|█████████▌| 316/330 [1:02:59<02:47, 11.96s/it, loss=2, v_num=0]loss embedd 0.4827863574028015\n",
      "loss 2.0004827976226807\n",
      "Epoch 1:  96%|█████████▌| 317/330 [1:03:12<02:35, 11.96s/it, loss=2, v_num=0]loss embedd 0.48078978061676025\n",
      "loss 2.000480890274048\n",
      "Epoch 1:  96%|█████████▋| 318/330 [1:03:25<02:23, 11.97s/it, loss=2, v_num=0]loss embedd 0.4787314534187317\n",
      "loss 2.000478744506836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danilo/GitHub/deep-learning/venv/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:686: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "triplet_trashbin_task = TripletNetworkTaskDebugged(squeezeNet_1_0, lr=0.002)\n",
    "logger = TensorBoardLogger(\"metric_logs\", name=\"test_trashbin_v1\",)\n",
    "\n",
    "# TODO: salva ogni ...\n",
    "# TODO: CALLBACK!!!!!\n",
    "trainer = pl.Trainer(gpus=GPUS, logger = logger, max_epochs = 10, check_val_every_n_epoch = 5, )\n",
    "trainer.fit(triplet_trashbin_task, triplet_dataset_train_loader, triplet_dataset_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: controlla i commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: devo estrarre TSNE??\n",
    "# Come continuo ???"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b5afb9c6c69ce826c7b3420d962c361055e44e7f6b101c54e3065067bcff4ff"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
