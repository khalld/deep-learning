{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/khalld/deep-learning.git\n",
    "!mv deep-learning dl\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pytorch_lightning as pl\n",
    "except ModuleNotFoundError:\n",
    "    !pip install --quiet pytorch-lightning>=1.4\n",
    "try:\n",
    "    import faiss\n",
    "except ModuleNotFoundError:\n",
    "    !pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from libs.code import *\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from libs.Dataset import *\n",
    "from libs.util import *\n",
    "from libs.SiameseNetwork import TripletNetworkTask\n",
    "# non necessari !\n",
    "# from libs.code import *\n",
    "# from libs.VAE import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imposto i seed e le variabili globali:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1996)\n",
    "np.random.seed(1996)\n",
    "pl.seed_everything(1996)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.determinstic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DST = 'dataset/all_labels.csv'\n",
    "PATH_GDRIVE = ''\n",
    "NUM_WORKERS = 8\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 4\n",
    "GPUS = 0\n",
    "PRETRAINED_MODEL_PATH =  'models/squeezeNet_pretrained.pth'\n",
    "num_class = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carico il dataset singolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valori pretrained\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225] \n",
    "\n",
    "transforms = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor(), transforms.Normalize(mean=mean, std=std)])\n",
    "\n",
    "dst = TrashbinDataset(csv=PATH_DST, transform=transforms)\n",
    "\n",
    "dst_train, dst_test = split_into_train_and_test(dst)\n",
    "\n",
    "dst_train_loader = DataLoader(dst_train, num_workers=NUM_WORKERS, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dst_test_loader = DataLoader(dst_test, num_workers=NUM_WORKERS, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estraggo le rappresentazioni rgb dai loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_train_rep_rgb, dst_train_labels = extract_rgb_representations(loader=dst_train_loader)\n",
    "dst_test_rep_rgb, dst_test_labels = extract_rgb_representations(loader=dst_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rappresentazioni di training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_train_rep_rgb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ottengo le predizioni sul test-set usando `predict_nn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_label_rgb = predict_nn(dst_train_rep_rgb, dst_test_rep_rgb, dst_train_labels)\n",
    "print(f\"Sample di label: {pred_test_label_rgb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valuto le performance della baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_error = evaluate_classification(pred_test_label_rgb, dst_test_labels)\n",
    "print(f\"Classification error: {classification_error:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importo per effettuare il training della triplenet il miglior modello trovato nella precedente relazione: `SqueezeNet v1.0`. Importo dunque i pesi già trovati dopo il training di 100 epoche .... <b>TODO migliora la descrizione</b> ... importo i pesi.. faccio le opportune modifiche ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scarico il modello da pytorch\n",
    "squeezeNet_1_0 = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_0', pretrained=True)\n",
    "# applico le opportune modifiche\n",
    "squeezeNet_1_0.classifier[1] = nn.Conv2d(512, num_class, kernel_size=(1,1), stride=(1,1))\n",
    "squeezeNet_1_0.num_classes = num_class\n",
    "# carico i pesi salvati\n",
    "squeezeNet_1_0.load_state_dict(torch.load(PRETRAINED_MODEL_PATH))\n",
    "\n",
    "# riduco l'ultimo modello alla funzione attività:\n",
    "squeezeNet_1_0.classifier = nn.Identity()\n",
    "squeezeNet_1_0(torch.zeros(1, 3, 224,224)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uso il modello, allenato nel precedente progetto, per estrarre le rappresentazioni dal training e dal test set\n",
    "dst_train_rep, dst_train_labels = extract_rep_squeezeNet(squeezeNet_1_0, dst_train_loader)\n",
    "dst_test_rep, dst_test_labels = extract_rep_squeezeNet(squeezeNet_1_0, dst_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valuto le performance del sistema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valuto le performance del sistema con rappresentazioni non ancora ottimizzate\n",
    "pred_test_label = predict_nn(dst_train_rep, dst_test_rep, dst_train_labels)\n",
    "classification_error = evaluate_classification(pred_test_label, dst_test_labels)\n",
    "print(f\"Classification error: {classification_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carico il dataset in triplette:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_triplet = TripletTrashbin(root=PATH_DST, transform=transforms)\n",
    "\n",
    "dst_train_triplet, dst_test_triplet = split_into_train_and_test(dst_triplet)\n",
    "\n",
    "triplet_dataset_train_loader = DataLoader(dst_train_triplet, num_workers=NUM_WORKERS, batch_size=BATCH_SIZE, shuffle=True)\n",
    "triplet_dataset_test_loader = DataLoader(dst_test_triplet, num_workers=NUM_WORKERS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: mostra le immagini delle triplette"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alleno la rete con lr=0.002 che è il migliore trovato per SqueezeNet nel precedente progetto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_trashbin_task =  TripletNetworkTask(squeezeNet_1_0, lr=0.002)\n",
    "logger = TensorBoardLogger(\"metric_logs\", name=\"test_trashbin_v1\",\n",
    "                            callbacks=[\n",
    "                                ModelCheckpoint(save_weights_only=True, every_n_epochs=2),    # default save checkpoint every 10 times\n",
    "                                LearningRateMonitor(\"epoch\")\n",
    "                                ], )\n",
    "\n",
    "# TODO: salva ogni ...\n",
    "# TODO: CALLBACK!!!!!\n",
    "trainer = pl.Trainer(gpus=GPUS, logger = logger, max_epochs = 10, check_val_every_n_epoch=5, )\n",
    "trainer.fit(triplet_trashbin_task, triplet_dataset_train_loader, triplet_dataset_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: devo estrarre TSNE??\n",
    "# Come continuo ???"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b5afb9c6c69ce826c7b3420d962c361055e44e7f6b101c54e3065067bcff4ff"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
