{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/khalld/deep-learning.git\n",
    "!mv deep-learning dl\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.code import *\n",
    "import torch\n",
    "from torch.utils import data # necessary to create a map-style dataset https://pytorch.org/docs/stable/data.html\n",
    "from os.path import splitext, join\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "from torch import nn\n",
    "from torch.optim import SGD\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.manifold import TSNE\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import random\n",
    "from random import choice\n",
    "\n",
    "np.random.seed(1996)\n",
    "torch.manual_seed(1996)\n",
    "random.seed(1996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DST = join('dataset', 'all_labels.csv')\n",
    "PATH_GDRIVE = ''\n",
    "NUM_WORKERS = 6 # vecchio progetto 2 ma il pc è più potente\n",
    "BATCH_SIZE = 32 # come nel vecchio progetto\n",
    "NUM_EPOCHS = 1\n",
    "GPUS = 0\n",
    "\n",
    "# mean and dev std of MNIST\n",
    "mean = 0.1307\n",
    "std = 0.3081\n",
    "\n",
    "dataset_df = pd.read_csv(join(PATH_GDRIVE, PATH_DST))\n",
    "\n",
    "dic_dst = {\n",
    "    0: 'empty',\n",
    "    1: 'half',\n",
    "    2: 'full'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir metric_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Autoencoders - Extract codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Start making triplets... *****\n",
      "Triplets process ended\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "                                transforms.Grayscale(num_output_channels=1), #TODO: immagini in bianco e nero x semplificare e farlo uguale al prof\n",
    "                                transforms.Resize((28,28)),  # # 256 x 256 nel vecchio progetto\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((mean,),(std)),\n",
    "                                ])\n",
    "\n",
    "dataset_triplet = TripletTrashbin(root=PATH_DST, transform=transform)\n",
    "\n",
    "# ***** Visualizzo la rete triplet implmentata ***** TODO: fai meglio\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizzo il dataset adattato al task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,4))\n",
    "for ii, i in enumerate(np.random.choice(range(len(dataset_triplet)), 3)):\n",
    "    plt.subplot(3, 10, ii+1)\n",
    "    # plt.text(3,10, 'Main element %i' % (i))\n",
    "    plt.imshow(dataset_triplet[i][0],)\n",
    "    \n",
    "    # plt.text(3,10, 'Similar to %i' % (i))\n",
    "    plt.subplot(3, 10, ii+11)\n",
    "    plt.imshow(dataset_triplet[i][1])\n",
    "\n",
    "    # plt.text(3,10, 'Dissimilar to %i' % (i))\n",
    "    plt.subplot(3, 10, ii+21)\n",
    "    plt.imshow(dataset_triplet[i][2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'split_into_train_and_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xc/1c23sj2s5h7d869ldsyfkyk40000gn/T/ipykernel_3036/1279867783.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset_train_triplet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_test_triplet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_into_train_and_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_triplet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataset_train_loader_triplet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_train_triplet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_WORKERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataset_test_loader_triplet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_test_triplet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_WORKERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#dataset_validation_loader = ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'split_into_train_and_test' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_train_triplet, dataset_test_triplet = split_into_train_and_test(dataset_triplet)\n",
    "\n",
    "dataset_train_loader_triplet = DataLoader(dataset_train_triplet, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True)\n",
    "dataset_test_loader_triplet = DataLoader(dataset_test_triplet, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "#dataset_validation_loader = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_trashbin_task = TripletNetworkTask(embedding_net=EmbeddingNet())\n",
    "logger = TensorBoardLogger(\"metric_logs\", name=\"siamese_triplet\")\n",
    "trainer = pl.Trainer(gpus=GPUS, logger=logger, max_epochs=NUM_EPOCHS, progress_bar_refresh_rate=0)\n",
    "trainer.fit(triplet_trashbin_task, dataset_train_loader_triplet, dataset_test_loader_triplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trashbin_test_representations, trashbin_test_labels = extract_representations(triplet_trashbin_task.embedding_net, dataset_train_loader_triplet)\n",
    "selected_rep = np.random_choice(len(trashbin_test_representations), 1000)\n",
    "selected_tb_test_representations = trashbin_test_representations[selected_rep]\n",
    "selected_tb_test_labels = trashbin_test_labels[selected_rep]\n",
    "\n",
    "tsne = TSNE(2)\n",
    "rep_tsne = tsne.fit_transform(selected_tb_test_representations)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for c in np.unique(selected_tb_test_labels):\n",
    "    plt.plot(rep_tsne[selected_tb_test_labels == c, 0], rep_tsne[selected_tb_test_labels == c], 'o', label=c)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b5afb9c6c69ce826c7b3420d962c361055e44e7f6b101c54e3065067bcff4ff"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
