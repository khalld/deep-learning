{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from libs.code import *\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from libs.VAE import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.determinstic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "\n",
    "PATH_DST = 'dataset/all_labels.csv'\n",
    "PATH_GDRIVE = ''\n",
    "NUM_WORKERS = 4\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 5\n",
    "GPUS = 0\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                                transforms.Resize((32,32)),\n",
    "                                transforms.ToTensor(),\n",
    "                                # torch.flatten # trasforma il tensore ad una dimensione\n",
    "                                ])\n",
    "\n",
    "dataset = TrashbinDataset(csv=PATH_DST, transform=transform)\n",
    "\n",
    "# TODO: fixa la funzione!\n",
    "dataset_train, dataset_test = split_into_train_and_test(dataset)\n",
    "_, dataset_val = split_into_train_and_test(dataset)\n",
    "\n",
    "train_loader = data.DataLoader(dataset_train, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True)\n",
    "val_loader = data.DataLoader(dataset_val, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False)\n",
    "test_loader = data.DataLoader(dataset_test, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(latent_dim, checkpoint_path, name):\n",
    "    # Create a PyTorch Lightning trainer with the generation callback\n",
    "\n",
    "    my_logger = TensorBoardLogger(save_dir=f\"{checkpoint_path}_logger\", name= f\"{name}_{latent_dim}\")\n",
    "\n",
    "    trainer = pl.Trainer(default_root_dir=os.path.join(f\"{checkpoint_path}_trainer\", f\"{name}_{latent_dim}\"), \n",
    "                        gpus=1 if str(device).startswith(\"cuda\") else 0, \n",
    "                        max_epochs=10, \n",
    "                        callbacks=[ModelCheckpoint(save_weights_only=True),\n",
    "                                    GenerateCallback(get_train_images(8), every_n_epochs=2),\n",
    "                                    LearningRateMonitor(\"epoch\")]\n",
    "                        ,logger=my_logger)\n",
    "                        \n",
    "    # trainer.logger._log_graph = True         # If True, we plot the computation graph in tensorboard\n",
    "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
    "    \n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(checkpoint_path, f\"{name}_{latent_dim}.ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(\"Found pretrained model, loading...*****\")\n",
    "        model = Autoencoder.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        model = Autoencoder(base_channel_size=32, latent_dim=latent_dim)\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "    \n",
    "    # Test best model on validation and test set\n",
    "    val_result = trainer.test(model, test_dataloaders=val_loader, verbose=False)\n",
    "    test_result = trainer.test(model, test_dataloaders=test_loader, verbose=False)\n",
    "    result = {\"test\": test_result, \"val\": val_result}\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "for latent_dim in [64, 128, 256, 384]:\n",
    "    model_ld, result_ld = train(latent_dim, f\"VAE_{latent_dim}\", f\"VAE_{latent_dim}\")\n",
    "    model_dict[latent_dim] = {\"model\": model_ld, \"result\": result_ld}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
